{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stylo in Python\n",
    "\n",
    "\n",
    "## Why would you do that?\n",
    "\n",
    "Since a couple of years I have been using stylometric methods to analyse texts, mainly literary ones. I learned about the great stylometric tool Stylo (written in R) at the European Summer School of Digital Humanities in Leipzig from two of the developers: Maciej Eder and Jan Rybicki. \n",
    "\n",
    "Some months after that I started my PhD at the University of Würzburg at the Computerphilologie Professorship (hold by Prof. Jannidis). I was told that I had to learn Python because that was the *programming mother tongue* of the department. So I did. Since then many of my projects are a mix of very basic R script that call Stylo and other more sofisticated scripts that make the preprocess and the evaluation in Python.\n",
    "\n",
    "I am not the only person in this R-Python situation and actually in the last years at least two tools for Stylometry have been written in Python: Pystyl and PyDelta. Why do I keep working with Stylo if I know more Python? For several reasons:\n",
    "\n",
    " * Stylo is very well documented\n",
    " * It has a mailing group where you get answers and help\n",
    " * It has been tested by hundreds of researchers\n",
    " * The developers teach about the tool\n",
    " * And they use the feedback of these workshops (we are talking about hundreds of students!) to improve Stylo (I have seen myself Maciej speed coding some changes in Stylo during the class, uploading to CRAN, and asking the people to update Stylo)\n",
    " * Because my PhD-tutors recommend me to do so\n",
    "\n",
    "My stylometric tests are  becoming more and more complex so it is starting to be a pain to jump all the time between two groups of scripts. I knew that you can use other programming languages inside Python, so I thought that it was worth a try to see if it was possible with R too.\n",
    "\n",
    "This Notebook and the sibling blog post at http://cligs.hypotheses.org/blog are the first findings. I would be really happy to receive opinion and feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rpy2\n",
    "The module that we are going to use is *rpy2* https://rpy2.readthedocs.io/en/version_2.8.x/, which allows you to work with R in Python. Installing rpy2 was not the difficult part, the difficult part was to make it work. After some time I realised that the problem was the version of R in my computer. Although the documentation of rpy2 says that a 3.0 version of R should be ok, it was not. Updating R in Ubuntu was trickier than expected, so I uninstalled and reinstalled R and Stylo again, making sure that the version was higher than 3.0. I am currently working with 3.3.\n",
    "\n",
    "So, enough talking, let's do some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of R that is been used: 3.3\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as ro\n",
    "R = ro.r\n",
    "print(\"Version of R that is been used: \"+ str(R.version[6][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not going to explain how exactly rpy2 works (because it is not the poing of this notebook and because I couldn't). Let's just say that when we see anything starting with an R., it will be a R object that we calling from Python. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rpy2.robjects.vectors.FloatVector'>\n",
      "[1] 3.141593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R.pi\n",
    "print(type(R.pi))\n",
    "print(R.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert this objects to Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "pi = R.pi[0]\n",
    "print(type(pi))\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stylo in Python\n",
    "In the same way we can call Stylo in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Help on ‘stylo’stylo                  package:stylo                   R Documentation\n",
      "\n",
      "_\bS_\bt_\by_\bl_\bo_\bm_\be_\bt_\br_\bi_\bc _\bm_\bu_\bl_\bt_\bi_\bd_\bi_\bm_\be_\bn_\bs_\bi_\bo_\bn_\ba_\bl _\ba_\bn_\ba_\bl_\by_\bs_\be_\bs\n",
      "\n",
      "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
      "\n",
      "     It is quite a long story what this function does. Basically, it is\n",
      "     an all-in-one tool for a variety of experiments in computational\n",
      "     stylistics. For a more detailed description, refer to HOWTO\n",
      "     available at: <URL:\n",
      "     https://sites.google.com/site/computationalstylistics/>\n",
      "\n",
      "_\bU_\bs_\ba_\bg_\be:\n",
      "\n",
      "     stylo(gui = TRUE, frequencies = NULL, parsed.corpus = NULL,\n",
      "           features = NULL, path = NULL, corpus.dir = \"corpus\", ...)\n",
      "     \n",
      "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
      "\n",
      "     gui: an optional argument; if switched on, a simple yet effective\n",
      "          graphical interface (GUI) will appear. Default value is\n",
      "          ‘TRUE’.\n",
      "\n",
      "frequencies: using this optional argument, one can load a custom table\n",
      "          containing frequencies/counts for several variables, e.g.\n",
      "          most frequent words, across a number of text samples. It can\n",
      "          be either an R object (matrix or data frame), or a filename\n",
      "          containing tab-delimited data. If you use an R object, make\n",
      "          sure that the rows contain samples, and the columns -\n",
      "          variables (words). If you use an external file, the variables\n",
      "          should go vertically (i.e. in rows): this is because files\n",
      "          containing vertically-oriented tables are far more flexible\n",
      "          and easily editable using, say, Excel or any text editor.  To\n",
      "          flip your table horizontally/vertically use the generic\n",
      "          function t().\n",
      "\n",
      "parsed.corpus: another option is to pass a pre-processed corpus as an\n",
      "          argument. It is assumed that this object is a list, each\n",
      "          element of which is a vector containing one tokenized sample.\n",
      "          The example shown below will give you some hints how to\n",
      "          prepare such a corpus.\n",
      "\n",
      "features: usually, a number of the most frequent features (words, word\n",
      "          n-grams, character n-grams) are extracted automatically from\n",
      "          the corpus, and they are used as variables for further\n",
      "          analysis. However, in some cases it makes sense to use a set\n",
      "          of tailored features, e.g.  the words that are associated\n",
      "          with emotions or, say, a specific subset of function words.\n",
      "          This optional argument allows to pass either a filename\n",
      "          containing your custom list of features, or a vector (R\n",
      "          object) of features to be assessed.\n",
      "\n",
      "    path: if not specified, the current directory will be used for\n",
      "          input/output procedures (reading files, outputting the\n",
      "          results).\n",
      "\n",
      "corpus.dir: the subdirectory (within the current working directory)\n",
      "          that contains the corpus text files. If not specified, the\n",
      "          default subdirectory ‘corpus’ will be used. This option is\n",
      "          immaterial when an external corpus and/or external table with\n",
      "          frequencies is loaded.\n",
      "\n",
      "     ...: any variable produced by ‘stylo.default.settings’ can be set\n",
      "          here, in order to overwrite the default values. An example of\n",
      "          such a variable is ‘network = TRUE’ (switched off as default)\n",
      "          for producing stylometric bootstrap consensus networks (Eder,\n",
      "          forthcoming); the function saves a csv file, containing a\n",
      "          list of nodes that can be loaded into, say, Gephi.\n",
      "\n",
      "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
      "\n",
      "     If no additional argument is passed, then the functions tries to\n",
      "     load text files from the default subdirectory ‘corpus’.  There are\n",
      "     a lot of additional options that should be passed to this\n",
      "     function; they are all loaded when ‘stylo.default.settings’ is\n",
      "     executed (which is typically called automatically from inside the\n",
      "     ‘stylo’ function).\n",
      "\n",
      "_\bV_\ba_\bl_\bu_\be:\n",
      "\n",
      "     The function returns an object of the class ‘stylo.results’: a\n",
      "     list of variables, including a table of word frequencies, vector\n",
      "     of features used, a distance table and some more stuff.\n",
      "     Additionally, depending on which options have been chosen, the\n",
      "     function produces a number of files containing results, plots,\n",
      "     tables of distances, etc.\n",
      "\n",
      "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
      "\n",
      "     Maciej Eder, Jan Rybicki, Mike Kestemont\n",
      "\n",
      "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
      "\n",
      "     Eder, M. Kestemont, M. and Rybicki, J. (2013). Stylometry with R:\n",
      "     a suite of tools. In: \"Digital Humanities 2013: Conference\n",
      "     Abstracts\".  University of Nebraska-Lincoln, Lincoln, NE, pp.\n",
      "     487-89.\n",
      "\n",
      "     Eder, M. (forthcoming). Visualization in stylometry: some problems\n",
      "     and solutions.\n",
      "\n",
      "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
      "\n",
      "     ‘classify’, ‘oppose’, ‘rolling.classify’\n",
      "\n",
      "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
      "\n",
      "     ## Not run:\n",
      "     \n",
      "     # standard usage (it builds a corpus from a set of text files):\n",
      "     stylo()\n",
      "     \n",
      "     # loading word frequencies from a tab-delimited file:\n",
      "     stylo(frequencies = \"my_frequencies.txt\")\n",
      "     \n",
      "     # using an existing corpus (a list containing tokenized texts):\n",
      "     txt1 = c(\"to\", \"be\", \"or\", \"not\", \"to\", \"be\")\n",
      "     txt2 = c(\"now\", \"i\", \"am\", \"alone\", \"o\", \"what\", \"a\", \"slave\", \"am\", \"i\")\n",
      "     txt3 = c(\"though\", \"this\", \"be\", \"madness\", \"yet\", \"there\", \"is\", \"method\")\n",
      "     custom.txt.collection = list(txt1, txt2, txt3)\n",
      "       names(custom.txt.collection) = c(\"hamlet_A\", \"hamlet_B\", \"polonius_A\")\n",
      "     stylo(parsed.corpus = custom.txt.collection)\n",
      "     \n",
      "     # using a custom set of features (words, n-grams) to be analyzed:\n",
      "     my.selection.of.function.words = c(\"the\", \"and\", \"of\", \"in\", \"if\", \"into\", \n",
      "                                        \"within\", \"on\", \"upon\", \"since\")\n",
      "     stylo(features = my.selection.of.function.words)\n",
      "     \n",
      "     # loading a custom set of features (words, n-grams) from a file:\n",
      "     stylo(features = \"wordlist.txt\")\n",
      "     \n",
      "     # batch mode, custom name of corpus directory:\n",
      "     my.test = stylo(gui = FALSE, corpus.dir = \"ShakespeareCanon\")\n",
      "     summary(my.test)\n",
      "     \n",
      "     # batch mode, character 3-grams requested:\n",
      "     stylo(gui = FALSE, analyzed.features = \"c\", ngram.size = 3)\n",
      "     ## End(Not run)\n",
      "     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "R.library(\"stylo\")\n",
    "\n",
    "print(R.help(\"stylo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the repository if this Notebook you find in a subfolder a one Spanish repository  of the CLiGS Textbox (https://github.com/cligs/textbox) that are already prepared for stylometric tests. So I will define the path just as the current place and I will call Stylo without the graphical user interface (if I would need the GUI we would just work in R!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using current directory...\n",
      "\n",
      "Performing no sampling (using entire text as sample)\n",
      "\n",
      "loading Bazan_Pazos-ne0077.txt\t...\n",
      "\n",
      "loading Bazan_Piedra-ne0082.txt\t...\n",
      "\n",
      "loading Bazan_Sirena-ne0085.txt\t...\n",
      "\n",
      "loading BlascoIbanez_Arroz-ne0163.txt\t...\n",
      "\n",
      "loading BlascoIbanez_Barraca-ne0164.txt\t...\n",
      "\n",
      "loading BlascoIbanez_Bodega-ne0019.txt\t...\n",
      "\n",
      "loading Clarin_Cuesta-ne0170.txt\t...\n",
      "\n",
      "loading Clarin_Hijo-ne0135.txt\t...\n",
      "\n",
      "loading Clarin_Regenta-ne0325.txt\t...\n",
      "\n",
      "loading Galdos_Bringas-ne0027.txt\t...\n",
      "\n",
      "loading Galdos_Misericordia-ne0002.txt\t...\n",
      "\n",
      "loading Galdos_Tristana-ne0005.txt\t...\n",
      "\n",
      "loading Miro_Amigo-ne0044.txt\t...\n",
      "\n",
      "loading Miro_Hilvan-ne0041.txt\t...\n",
      "\n",
      "loading Miro_Vivir-ne0042.txt\t...\n",
      "\n",
      "loading Pereda_Pedro-ne0144.txt\t...\n",
      "\n",
      "loading Pereda_Penas-ne0145.txt\t...\n",
      "\n",
      "loading Pereda_Sotileza-ne0146.txt\t...\n",
      "\n",
      "loading Picon_Dulce-ne0155.txt\t...\n",
      "\n",
      "loading Picon_JuanV-ne0162.txt\t...\n",
      "\n",
      "loading Picon_Lazaro-ne0161.txt\t...\n",
      "\n",
      "loading Valera_Genio-ne0151.txt\t...\n",
      "\n",
      "loading Valera_Juanita-ne0152.txt\t...\n",
      "\n",
      "loading Valera_Morsamor-ne0153.txt\t...\n",
      "\n",
      "slicing input text into tokens...\n",
      "\n",
      "turning words into features, e.g. char n-grams (if applicable)...\n",
      "\n",
      "\n",
      "\n",
      "Total nr. of samples in the corpus: \n",
      " \n",
      "24\n",
      " \n",
      "\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "\n",
      "The corpus consists of\n",
      " \n",
      "1827363\n",
      " \n",
      "tokens\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "culling @ \n",
      " \n",
      "0\n",
      " \n",
      "\t\n",
      " \n",
      "available features (words) \n",
      " \n",
      "5000\n",
      " \n",
      "\n",
      "\n",
      "Calculating z-scores... \n",
      "\n",
      "\n",
      "Calculating classic Delta distances... \n",
      "\n",
      "MFW used: \n",
      "100\n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: processing  24  text samples\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: .\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning:        \n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: combining frequencies into a table...\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "R.setwd(\".\")\n",
    "all_data = R.stylo(\n",
    "            gui = False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is cool to see the answers of Stylo in a Jupyter Notebook running on Python, right? It sends us a couple of warning messages: I think the problem is in the kind of answer that Stylo gives you in command line of R while running, that cannot give you in the same ways in Python.\n",
    "\n",
    "When it is finished, a pop-up window from R will appear with the classic dendrogram that we all know:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](dendrogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing arguments\n",
    "Now, what happens when I want to define the arguments of Stylo? Because, as explained in the documentation, the arguments to define the maximum and minimum MFW are called *mfw.min* and *mfw.max*. I wee try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-56-5f8daf7e2087>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-56-5f8daf7e2087>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    mfw.min = 5000,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "R.setwd(\".\")\n",
    "all_data = R.stylo(\n",
    "            gui = False,\n",
    "            mfw.min = 5000,\n",
    "            mfw.max = 5000\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python complains: it doesn't expect a dot in a variable name. For this cases the documentation of rpy2 (http://rpy.sourceforge.net/rpy2/doc-2.2/html/robjects_functions.html) recommends to pass the arguments as a python dictionary in which the keys are strings with the names of the arguments in Stylo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using current directory...\n",
      "\n",
      "Performing no sampling (using entire text as sample)\n",
      "\n",
      "loading Bazan_Pazos-ne0077.txt\t...\n",
      "\n",
      "loading Bazan_Piedra-ne0082.txt\t...\n",
      "\n",
      "loading Bazan_Sirena-ne0085.txt\t...\n",
      "\n",
      "loading BlascoIbanez_Arroz-ne0163.txt\t...\n",
      "\n",
      "loading BlascoIbanez_Barraca-ne0164.txt\t...\n",
      "\n",
      "loading BlascoIbanez_Bodega-ne0019.txt\t...\n",
      "\n",
      "loading Clarin_Cuesta-ne0170.txt\t...\n",
      "\n",
      "loading Clarin_Hijo-ne0135.txt\t...\n",
      "\n",
      "loading Clarin_Regenta-ne0325.txt\t...\n",
      "\n",
      "loading Galdos_Bringas-ne0027.txt\t...\n",
      "\n",
      "loading Galdos_Misericordia-ne0002.txt\t...\n",
      "\n",
      "loading Galdos_Tristana-ne0005.txt\t...\n",
      "\n",
      "loading Miro_Amigo-ne0044.txt\t...\n",
      "\n",
      "loading Miro_Hilvan-ne0041.txt\t...\n",
      "\n",
      "loading Miro_Vivir-ne0042.txt\t...\n",
      "\n",
      "loading Pereda_Pedro-ne0144.txt\t...\n",
      "\n",
      "loading Pereda_Penas-ne0145.txt\t...\n",
      "\n",
      "loading Pereda_Sotileza-ne0146.txt\t...\n",
      "\n",
      "loading Picon_Dulce-ne0155.txt\t...\n",
      "\n",
      "loading Picon_JuanV-ne0162.txt\t...\n",
      "\n",
      "loading Picon_Lazaro-ne0161.txt\t...\n",
      "\n",
      "loading Valera_Genio-ne0151.txt\t...\n",
      "\n",
      "loading Valera_Juanita-ne0152.txt\t...\n",
      "\n",
      "loading Valera_Morsamor-ne0153.txt\t...\n",
      "\n",
      "slicing input text into tokens...\n",
      "\n",
      "turning words into features, e.g. char n-grams (if applicable)...\n",
      "\n",
      "\n",
      "\n",
      "Total nr. of samples in the corpus: \n",
      " \n",
      "24\n",
      " \n",
      "\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "\n",
      "The corpus consists of\n",
      " \n",
      "1827363\n",
      " \n",
      "tokens\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "culling @ \n",
      " \n",
      "0\n",
      " \n",
      "\t\n",
      " \n",
      "available features (words) \n",
      " \n",
      "5000\n",
      " \n",
      "\n",
      "\n",
      "Calculating z-scores... \n",
      "\n",
      "\n",
      "Calculating Eder's Delta distances... \n",
      "\n",
      "MFW used: \n",
      "5000\n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: processing  24  text samples\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: .\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning:        \n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: combining frequencies into a table...\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "I_love_this_stuff = R.stylo(\n",
    "    **{\n",
    "        \"gui\" : False,\n",
    "        \"analyzed.features\" : \"w\",\n",
    "        \"ngram.size\" : 1,\n",
    "        \"preserve.case\" : False,\n",
    "        \"mfw.min\" : 5000,\n",
    "        \"mfw.max\" : 5000,\n",
    "        \"mfw.list.cutoff\" : 5000,\n",
    "        \"analysis.type\" : \"CA\",\n",
    "        \"distance.measure\" : \"dist.eder\",\n",
    "        \"sampling\" : \"no.sampling\",\n",
    "        \"display.on.screen\" : False,\n",
    "        \"write.png.file\" : True,\n",
    "        \"save.distance.tables\" : True,\n",
    "        \"save.analyzed.features\" : True,\n",
    "        \"save.analyzed.freqs\" : True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have in our folder all the files that we have asked: png, distance table, features used... But what if I want to work further with this data in Python?\n",
    "\n",
    "## Using the data from Stylo in Python\n",
    "\n",
    "In the cell above I have called stylo() and saved its output in a variable called I_love_this_stuff (following the documentation of stylo ;) ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rpy2.robjects.vectors.ListVector'>\n",
      "9\n",
      "\n",
      "Function call:\n",
      "(function (gui = TRUE, frequencies = NULL, parsed.corpus = NULL,      features = NULL, path = NULL, corpus.dir = \"corpus\", ...)  {     passed.arguments = list(...)     original.path = getwd()     if (is.character(path) == TRUE & length(path) > 0) {         if (file.exists(path) == TRUE & file.info(path)[2] ==              TRUE) {             setwd(path)         }         else {             stop(\"there is no directory \", getwd(), \"/\", path)         }     }     else {         cat(\"using current directory...\\n\")     }     if (is.character(corpus.dir) == FALSE | nchar(corpus.dir) ==          0) {         corpus.dir = \"corpus\"     }     variables = stylo.default.settings(...)     if (gui == TRUE) {         if (.Platform$OS.type == \"windows\" || .Platform$GUI ==              \"AQUA\" || (capabilities(\"tcltk\") && capabilities(\"X11\") &&              suppressWarnings(tcltk::.TkUp))) {             variables = gui.stylo(...)         }         else {             cat(\"\\n\")             cat(\"GUI could not be launched -- default settings will be used;\\n\")             cat(\"otherwise please pass your variables as command-line agruments\\n\\n\")         }     }     add.to.margins = variables$add.to.margins     analysis.type = variables$analysis.type     analyzed.features = variables$analyzed.features     classification.method = variables$classification.method     colors.on.graphs = variables$colors.on.graphs     consensus.strength = variables$consensus.strength     corpus.format = variables$corpus.format     corpus.lang = variables$corpus.lang     culling.incr = variables$culling.incr     culling.max = variables$culling.max     culling.min = variables$culling.min     culling.of.all.samples = variables$culling.of.all.samples     custom.graph.title = variables$custom.graph.title     delete.pronouns = variables$delete.pronouns     dendrogram.layout.horizontal = variables$dendrogram.layout.horizontal     display.on.screen = variables$display.on.screen     distance.measure = variables$distance.measure     dump.samples = variables$dump.samples     final.ranking.of.candidates = variables$final.ranking.of.candidates     how.many.correct.attributions = variables$how.many.correct.attributions     interactive.files = variables$interactive.files     k.value = variables$k.value     l.value = variables$l.value     label.offset = variables$label.offset     mfw.incr = variables$mfw.incr     mfw.list.cutoff = variables$mfw.list.cutoff     mfw.max = variables$mfw.max     mfw.min = variables$mfw.min     ngram.size = variables$ngram.size     preserve.case = variables$preserve.case     number.of.candidates = variables$number.of.candidates     outputfile = variables$outputfile     passed.arguments = variables$passed.arguments     pca.visual.flavour = variables$pca.visual.flavour     plot.custom.height = variables$plot.custom.height     plot.custom.width = variables$plot.custom.width     plot.font.size = variables$plot.font.size     plot.line.thickness = variables$plot.line.thickness     plot.options.reset = variables$plot.options.reset     reference.wordlist.of.all.samples = variables$reference.wordlist.of.all.samples     sample.size = variables$sample.size     sampling = variables$sampling     sampling.with.replacement = variables$sampling.with.replacement     save.analyzed.features = variables$save.analyzed.features     save.analyzed.freqs = variables$save.analyzed.freqs     save.distance.tables = variables$save.distance.tables     start.at = variables$start.at     svm.coef0 = variables$svm.coef0     svm.cost = variables$svm.cost     svm.degree = variables$svm.degree     svm.kernel = variables$svm.kernel     text.id.on.graphs = variables$text.id.on.graphs     titles.on.graphs = variables$titles.on.graphs     txm.compatibility.mode = variables$txm.compatibility.mode     use.custom.list.of.files = variables$use.custom.list.of.files     use.existing.freq.tables = variables$use.existing.freq.tables     use.existing.wordlist = variables$use.existing.wordlist     write.jpg.file = variables$write.jpg.file     write.pdf.file = variables$write.pdf.file     write.png.file = variables$write.png.file     write.svg.file = variables$write.svg.file     z.scores.of.all.samples = variables$z.scores.of.all.samples     linkage = variables$linkage     network = variables$network     network.tables = variables$network.tables     network.type = variables$network.type     linked.neighbors = variables$linked.neighbors     edge.weights = variables$edge.weights     relative.frequencies = variables$relative.frequencies     splitting.rule = variables$splitting.rule     preserve.case = variables$preserve.case     encoding = variables$encoding     stop.words = variables$stop.words     sample.overlap = variables$sample.overlap     number.of.samples = variables$number.of.samples     custom.graph.filename = variables$custom.graph.filename     pronouns = stylo.pronouns(language = corpus.lang)     mfw.min = round(mfw.min)     mfw.max = round(mfw.max)     mfw.incr = round(mfw.incr)     start.at = round(start.at)     culling.min = round(culling.min)     culling.max = round(culling.max)     culling.incr = round(culling.incr)     mfw.list.cutoff = round(mfw.list.cutoff)     sample.size = round(sample.size)     if (plot.options.reset == TRUE) {         plot.custom.height = 7         plot.custom.width = 7         plot.font.size = 10         plot.line.thickness = 1         plot.options.reset = FALSE     }     if (txm.compatibility.mode == TRUE) {         if (exists(\"txm.generated.freq.table\") == TRUE) {             if (exists(\"variable.name\") == FALSE) {                 variable.name = c()                 stop(\"TXM does not seem to pass any data to analyze\")             }             frequencies.0.culling = t(variable.name)             frequencies.0.culling = frequencies.0.culling[-1,                  ]             use.existing.freq.tables == TRUE         }         else {             cat(\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\",                  \"Oops! To use TXM compatibility mode, you have to launch TXM first!\\n\",                  \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\n\")             stop(\"Incorrect input data\")         }     }     if (use.existing.freq.tables == TRUE & file.exists(\"table_with_frequencies.txt\") ==          TRUE) {         frequencies = \"table_with_frequencies.txt\"     }     else {         use.existing.freq.tables = FALSE     }     if (use.existing.wordlist == TRUE & file.exists(\"wordlist.txt\") ==          TRUE) {         features = \"wordlist.txt\"     }     else {         use.existing.wordlist = FALSE     }     all.connections = 0     if (is.null(custom.graph.title) == FALSE) {         graph.title = as.character(custom.graph.title)[1]         graph.main.title = graph.title     }     else {         graph.title = basename(getwd())         graph.main.title = graph.title     }     if (text.id.on.graphs != \"both\") {         label.offset = 0     }     if (write.jpg.file == TRUE || write.png.file == TRUE) {         if (300 * plot.custom.width * 300 * plot.custom.height >              3.6e+07) {             cat(\"\\nYou have chosen a bitmap output format and quite a large plot area\\n\")             cat(\"of\", plot.custom.width, \"by\", plot.custom.height,                  \"inches. Producing some\", as.integer(300 * plot.custom.width *                    300 * plot.custom.height/1e+06), \"Megapixels will take a good while.\\n\\n\")             cat(\"  i - ignore this warning and continue with the current settings\\n\")             cat(\"  p - use pdf format instead of a bitmap (default)\\n\")             cat(\"  s - shrink the plot area to a reasonable size of 20x20 inches\\n\")             cat(\"  a - abort the script\\n\")             answer = readline(\"\\n[i/p/s/a]  \")             if (tolower(answer) == \"a\") {                 stop(\"The script stopped by the user\")             }             else if (tolower(answer) == \"i\") {                 cat(\"Okay (but honestly, do you really need such a large plot?)\\n\")             }             else if (tolower(answer) == \"s\") {                 cat(\"The plot area will be shrunken to 20x20 inches\\n\")                 plot.custom.width = 20                 plot.custom.height = 20             }             else {                 cat(\"Withdrawing from the bitmap output, performing pdf instead\\n\")                 write.jpg.file = FALSE                 write.svg.file = FALSE                 write.png.file = FALSE                 write.pdf.file = TRUE             }         }     }     features.exist = FALSE     if (length(features) > 1) {         if (is.vector(features) == TRUE) {             features = as.character(features)             mfw.list.of.all = features         }         else {             cat(\"\\n\")             cat(\"You seem to have chosen an existing set of features\\n\")             cat(\"Unfortunately, something is wrong: check if your variable\\n\")             cat(\"has a form of vector\\n\")             cat(\"\\n\")             stop(\"Wrong format: a vector of features (e.g. words) was expected\")         }         features.exist = TRUE     }     if (length(features) == 1) {         features = as.character(features)         if (file.exists(features) == TRUE) {             cat(\"\\n\", \"reading a custom set of features from a file...\",                  \"\\n\", sep = \"\")             features = scan(features, what = \"char\", sep = \"\\n\",                  encoding = encoding)             features = c(grep(\"^[^#]\", features, value = TRUE))             mfw.list.of.all = features         }         else {             cat(\"\\n\", \"file \\\"\", features, \"\\\" could not be found\\n\",                  sep = \"\")             stop(\"Wrong file name\")         }         features.exist = TRUE     }     corpus.exists = FALSE     if (length(frequencies) > 1) {         if (is.matrix(frequencies) == TRUE | is.data.frame(frequencies) ==              TRUE) {             frequencies = as.matrix(frequencies)         }         else {             cat(\"\\n\")             cat(\"You seem to have chosen an existing table with frequencies\\n\")             cat(\"Unfortunately, something is wrong: check if your variable\\n\")             cat(\"has a form of matrix/data frame\\n\")             cat(\"\\n\")             stop(\"Wrong format of the table of frequencies\")         }         if (length(colnames(frequencies)) == 0) {             colnames(frequencies) = paste(\"var\", 1:length(frequencies[1,                  ]), sep = \"_\")         }         if (length(rownames(frequencies)) == 0) {             rownames(frequencies) = paste(\"sample\", 1:length(frequencies[,                  1]), sep = \"_\")         }         corpus.exists = TRUE     }     if (length(frequencies) == 1) {         frequencies = as.character(frequencies)         if (file.exists(frequencies) == TRUE) {             cat(\"\\n\", \"reading a file containing frequencies...\",                  \"\\n\", sep = \"\")             frequencies = t(read.table(frequencies, encoding = encoding))         }         else {             cat(\"\\n\", \"file \\\"\", frequencies, \"\\\" could not be found\\n\",                  sep = \"\")             stop(\"Wrong file name\")         }         corpus.exists = TRUE     }     if (features.exist == TRUE & corpus.exists == TRUE) {         if (length(grep(\"TRUE\", colnames(frequencies) %in% features)) <              2) {             cat(\"The features you want to analyze do not match the variables' names:\\n\")             cat(\"\\n\")             cat(\"Available features:\", head(colnames(frequencies)),                  \"...\\n\")             cat(\"Chosen features:\", head(features), \"...\\n\")             cat(\"\\n\")             cat(\"Check the rotation of your table and the names of its rows and columns.\\n\")             stop(\"Input data mismatch\")         }         else {             frequencies = frequencies[, colnames(frequencies) %in%                  features]         }     }     if (features.exist == FALSE & corpus.exists == TRUE) {         features = colnames(frequencies)         mfw.list.of.all = features     }     if (corpus.exists == TRUE) {         if (length(frequencies[, 1]) < 2 | length(frequencies[1,              ]) < 2) {             cat(\"\\n\")             cat(\"There is not enough samples and/or features to be analyzed.\\n\")             cat(\"Try to use tables of at least two rows by two columns.\\n\")             cat(\"\\n\")             stop(\"Wrong size of the table of frequencies\")         }     }     if (corpus.exists == TRUE) {         frequencies.0.culling = frequencies     }     if (corpus.exists == FALSE & length(parsed.corpus) > 0) {         if (is.list(parsed.corpus) == TRUE & length(parsed.corpus) >              1) {             if (length(names(parsed.corpus)) != length(parsed.corpus)) {                 names(parsed.corpus) = paste(\"sample\", 1:length(parsed.corpus),                    sep = \"_\")             }             loaded.corpus = parsed.corpus             cat(\"Corpus loaded successfully.\\n\")             corpus.exists = TRUE         }         else {             cat(\"\\n\")             cat(\"The object you've specified as your corpus cannot be used.\\n\")             cat(\"It should be a list containing particular text samples\\n\")             cat(\"(vectors containing sequencies of words/n-grams or other features).\\n\")             cat(\"The samples (elements of the list) should have their names.\\n\")             cat(\"Alternatively, try to build your corpus from text files (default).\\n\")             cat(\"\\n\")             stop(\"Wrong corpus format\")         }     }     if (corpus.exists == FALSE) {         if (interactive.files == TRUE) {             setwd(corpus.dir)             corpus.filenames = basename(tk_choose.files(default = \"\",                  caption = \"Select at least 2 files\", multi = TRUE))             setwd(\"..\")         }         else {             if (use.custom.list.of.files == TRUE & file.exists(\"files_to_analyze.txt\") ==                  TRUE) {                 cat(\"\\n\")                 cat(\"external list of files will be used for uploading the corpus\\n\\n\")                 corpus.filenames = scan(\"files_to_analyze.txt\",                    what = \"char\", sep = \"\\n\", encoding = encoding,                    quiet = T)                 corpus.filenames = unlist(strsplit(corpus.filenames,                    \"[ \\t]+\"))                 if (length(setdiff(corpus.filenames, list.files(corpus.dir))) >                    0) {                   cat(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")                   cat(\"the following files have not been found:\\n\")                   cat(setdiff(corpus.filenames, list.files(corpus.dir)),                      \"\\n\\n\")                   cat(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")                   corpus.filenames = intersect(corpus.filenames,                      list.files(corpus.dir))                 }             }             else {                 corpus.filenames = list.files(corpus.dir)             }         }         if (file.exists(corpus.dir) == FALSE) {             cat(\"\\n\\n\", \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\",                  \"Hey! The working directory should contain the subdirectory \\\"\",                  corpus.dir, \"\\\"\\n\", \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\n\",                  sep = \"\")             setwd(original.path)             stop(\"Corpus prepared incorrectly\")         }         if (length(corpus.filenames) < 2 & sampling != \"normal.sampling\") {             cat(\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\",                  \"Ho! The subdirectory \\\"\", corpus.dir, \"\\\" should contain at least \\n          two text samples!\\n\",                  \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\n\",                  sep = \"\")             setwd(original.path)             stop(\"Corpus prepared incorrectly\")         }         if (sampling == \"normal.sampling\") {             cat(paste(\"Performing sampling (using sample size = \",                  sample.size, \" words)\\n\", sep = \"\"))         }         else if (sampling == \"random.sampling\") {             cat(paste(\"Performing random sampling (using random sample size = \",                  \" words)\\n\", sep = \"\"))         }         else if (sampling == \"no.sampling\") {             cat(paste(\"Performing no sampling (using entire text as sample)\",                  \"\\n\", sep = \"\"))         }         else {             stop(\"Exception raised: something is wrong with the sampling parameter you have \\n            specified...\")         }         loaded.corpus = load.corpus.and.parse(files = corpus.filenames,              corpus.dir = corpus.dir, encoding = encoding, markup.type = corpus.format,              language = corpus.lang, splitting.rule = splitting.rule,              sample.size = sample.size, sampling = sampling, sampling.with.replacement = sampling.with.replacement,              sample.overlap = sample.overlap, number.of.samples = number.of.samples,              features = analyzed.features, ngram.size = ngram.size,              preserve.case = preserve.case)     }     if (exists(\"frequencies.0.culling\") == FALSE) {         cat(\"\\n\")         cat(\"Total nr. of samples in the corpus: \", length(loaded.corpus),              \"\\n\")         if ((length(loaded.corpus) < 2) & (sampling == \"no.sampling\")) {             cat(\"\\n\\n\", \"your corpus folder seems to be empty!\",                  \"\\n\\n\")             stop(\"corpus error\")         }         if (features.exist == TRUE) {             cat(\"\\n\")             cat(\"using an existing wordlist (vector of features)...\\n\")             mfw.list.of.all = features         }         else {             wordlist.of.loaded.corpus = c()             for (file in 1:length(loaded.corpus)) {                 current.text = loaded.corpus[[file]]                 wordlist.of.loaded.corpus = c(wordlist.of.loaded.corpus,                    current.text)                 cat(\".\")                 if (file/25 == floor(file/25)) {                   cat(\"\\n\")                 }             }             cat(\"\\n\")             cat(\"The corpus consists of\", length(c(wordlist.of.loaded.corpus)),                  \"tokens\\n\")             mfw.list.of.all = sort(table(c(wordlist.of.loaded.corpus)),                  decreasing = T)             rm(wordlist.of.loaded.corpus)             if (length(mfw.list.of.all) > mfw.list.cutoff) {                 mfw.list.of.all = mfw.list.of.all[1:mfw.list.cutoff]             }             mfw.list.of.all = names(mfw.list.of.all)             cat(\"# This file contains the words that were used for building the table\",                  \"# of frequencies. It can be also used for further tasks, and for this\",                  \"# purpose it can be manually revised, edited, deleted, culled, etc.\",                  \"# You can either delete unwanted words, or mark them with \\\"#\\\"\",                  \"# -----------------------------------------------------------------------\",                  \"\", file = \"wordlist.txt\", sep = \"\\n\")             if (encoding == \"native.enc\") {                 data.to.be.saved = mfw.list.of.all             }             else {                 data.to.be.saved = iconv(mfw.list.of.all, to = encoding)             }             cat(data.to.be.saved, file = \"wordlist.txt\", sep = \"\\n\",                  append = T)         }         cat(\"\\n\")         if (dump.samples == TRUE) {             if (file.exists(\"sample_dump\")) {                 unlink(\"sample_dump\", recursive = TRUE)             }             dir.create(\"sample_dump\")             setwd(\"sample_dump\")             for (i in names(loaded.corpus)) {                 cat(loaded.corpus[[i]], file = paste(names(loaded.corpus[i]),                    \".txt\", sep = \"\"))             }             setwd(\"..\")         }         frequencies.0.culling = make.table.of.frequencies(corpus = loaded.corpus,              features = mfw.list.of.all, relative = relative.frequencies)         if (encoding == \"native.enc\") {             data.to.be.saved = t(frequencies.0.culling)         }         else {             data.to.be.saved = t(frequencies.0.culling)             rownames(data.to.be.saved) = iconv(rownames(data.to.be.saved),                  to = encoding)             colnames(data.to.be.saved) = iconv(colnames(data.to.be.saved),                  to = encoding)         }         write.table(data.to.be.saved, file = \"table_with_frequencies.txt\")     }     cat(\"\", file = \"stylo_config.txt\", append = F)     var.name <- function(x) {         if (is.character(x) == TRUE) {             cat(paste(deparse(substitute(x)), \" = \\\"\", x, \"\\\"\",                  sep = \"\"), file = \"stylo_config.txt\", sep = \"\\n\",                  append = T)         }         else {             cat(paste(deparse(substitute(x)), x, sep = \" = \"),                  file = \"stylo_config.txt\", sep = \"\\n\", append = T)         }     }     var.name(corpus.format)     var.name(corpus.lang)     var.name(analyzed.features)     var.name(ngram.size)     var.name(preserve.case)     var.name(encoding)     var.name(mfw.min)     var.name(mfw.max)     var.name(mfw.incr)     var.name(start.at)     var.name(culling.min)     var.name(culling.max)     var.name(culling.incr)     var.name(mfw.list.cutoff)     var.name(delete.pronouns)     var.name(use.existing.freq.tables)     var.name(use.existing.wordlist)     var.name(use.custom.list.of.files)     var.name(analysis.type)     var.name(consensus.strength)     var.name(sampling)     var.name(sample.size)     var.name(number.of.samples)     var.name(display.on.screen)     var.name(write.pdf.file)     var.name(write.jpg.file)     var.name(write.svg.file)     var.name(write.png.file)     var.name(plot.custom.height)     var.name(plot.custom.width)     var.name(plot.font.size)     var.name(plot.line.thickness)     var.name(text.id.on.graphs)     var.name(colors.on.graphs)     var.name(titles.on.graphs)     var.name(label.offset)     var.name(add.to.margins)     var.name(dendrogram.layout.horizontal)     var.name(pca.visual.flavour)     var.name(save.distance.tables)     var.name(save.analyzed.features)     var.name(save.analyzed.freqs)     var.name(dump.samples)     mfw.max.original = mfw.max     number.of.current.iteration = 0     if (analysis.type == \"BCT\") {         bootstrap.list = list()     }     if (culling.max >= 100) {         culling.max = 100     }     if (culling.min >= 100) {         culling.min = 100     }     if (culling.min <= 0) {         culling.min = 0     }     if (culling.max < culling.min) {         culling.max = culling.min     }     if (culling.incr <= 1) {         culling.incr = 10     }     for (j in (culling.min/culling.incr):(culling.max/culling.incr)) {         current.culling = j * culling.incr         table.with.all.freqs = perform.culling(frequencies.0.culling,              current.culling)         if (delete.pronouns == TRUE) {             table.with.all.freqs = delete.stop.words(table.with.all.freqs,                  pronouns)         }         if (is.vector(stop.words) == TRUE) {             table.with.all.freqs = delete.stop.words(table.with.all.freqs,                  stop.words)         }         table.with.all.freqs = table.with.all.freqs[, start.at:length(table.with.all.freqs[1,              ])]         if (mfw.max > length(table.with.all.freqs[1, ])) {             mfw.max = length(table.with.all.freqs[1, ])         }         if (mfw.min < 2) {             mfw.min = 2         }         if (mfw.max < mfw.min) {             mfw.max = mfw.min         }         if ((mfw.max != mfw.min) && (mfw.incr == 0)) {             mfw.incr = 10         }         cat(\"\\n\\n\")         cat(\"culling @ \", current.culling, \"\\t\", \"available features (words) \",              length(table.with.all.freqs[1, ]), \"\\n\")         if ((analysis.type == \"CA\") || (analysis.type == \"BCT\") ||              (analysis.type == \"MDS\")) {             cat(\"Calculating z-scores... \\n\\n\")             table.with.all.zscores = scale(table.with.all.freqs)             table.with.all.zscores = table.with.all.zscores[,                  ]         }         if ((analysis.type == \"CA\") || (analysis.type == \"BCT\") ||              (analysis.type == \"MDS\")) {             distance.name.on.graph = distance.measure             distance.name.on.file = distance.measure             if (distance.measure == \"delta\" | distance.measure ==                  \"dist.delta\") {                 cat(\"Calculating classic Delta distances... \\n\")                 distance.name.on.graph = \"Classic Delta distance\"                 distance.name.on.file = \"Classic Delta\"             }             else if (distance.measure == \"argamon\" | distance.measure ==                  \"dist.argamon\") {                 cat(\"Calculating Argamon's Delta distances... \\n\")                 distance.name.on.graph = \"Argamon's Delta distance\"                 distance.name.on.file = \"Argamon's Delta\"             }             else if (distance.measure == \"eder\" | distance.measure ==                  \"dist.eder\") {                 cat(\"Calculating Eder's Delta distances... \\n\")                 distance.name.on.graph = \"Eder's Delta distance\"                 distance.name.on.file = \"Eder's Delta\"             }             else if (distance.measure == \"simple\" | distance.measure ==                  \"dist.simple\") {                 cat(\"Calculating Eder's Simple distances... \\n\")                 distance.name.on.graph = \"Eder's Simple distance\"                 distance.name.on.file = \"Eder's Simple\"             }             else if (distance.measure == \"manhattan\" | distance.measure ==                  \"dist.manhattan\") {                 cat(\"Calculating Manhattan distances... \\n\")                 distance.name.on.graph = \"Manhattan distance\"                 distance.name.on.file = \"Manhattan\"             }             else if (distance.measure == \"canberra\" | distance.measure ==                  \"dist.canberra\") {                 cat(\"Calculating Canberra distances... \\n\")                 distance.name.on.graph = \"Canberra distance\"                 distance.name.on.file = \"Canberra\"             }             else if (distance.measure == \"euclidean\" | distance.measure ==                  \"dist.euclidean\") {                 cat(\"Calculating Euclidean distances... \\n\")                 distance.name.on.graph = \"Euclidean distance\"                 distance.name.on.file = \"Euclidean\"             }             else if (distance.measure == \"cosine\" | distance.measure ==                  \"dist.cosine\") {                 cat(\"Calculating Cosine distances... \\n\")                 distance.name.on.graph = \"Cosine distance\"                 distance.name.on.file = \"Cosine\"             }             else {                 distance.name.on.graph = paste(\"Distance:\", distance.measure)                 distance.name.on.file = distance.measure             }         }         cat(\"MFW used: \")         for (i in seq(mfw.min, mfw.max, round(mfw.incr))) {             mfw = i             if (mfw > length(colnames(table.with.all.freqs))) {                 mfw = length(colnames(table.with.all.freqs))             }             number.of.current.iteration = number.of.current.iteration +                  1             cat(mfw, \" \")             if ((analysis.type == \"CA\") || (analysis.type ==                  \"BCT\") || (analysis.type == \"MDS\")) {                 input.freq.table = table.with.all.freqs[, 1:mfw]                 supported.measures = c(\"dist.euclidean\", \"dist.manhattan\",                    \"dist.canberra\", \"dist.delta\", \"dist.eder\",                    \"dist.argamon\", \"dist.simple\", \"dist.cosine\")                 if (length(grep(distance.measure, supported.measures)) >                    1) {                   stop(\"Ambiguous distance method: which one did you want to use, really?\")                 }                 else if (length(grep(distance.measure, supported.measures)) ==                    0) {                   if (is.function(get(distance.measure)) == TRUE) {                     distance.table = do.call(distance.measure,                        list(x = input.freq.table))                     if (class(distance.table) != \"dist\") {                       stop(\"it wasn't a real distance measure function applied, was it?\")                     }                   }                 }                 else {                   distance = supported.measures[grep(distance.measure,                      supported.measures)]                   if (distance %in% c(\"dist.manhattan\", \"dist.euclidean\",                      \"dist.canberra\")) {                     distance = gsub(\"dist.\", \"\", distance)                     distance.table = as.matrix(dist(input.freq.table,                        method = distance))                   }                   else if (distance %in% c(\"dist.simple\", \"dist.cosine\")) {                     distance.table = do.call(distance, list(x = input.freq.table))                   }                   else {                     distance.table = do.call(distance, list(x = table.with.all.zscores[,                        1:mfw], scale = FALSE))                   }                 }                 distance.table = as.matrix(distance.table)                 rownames(distance.table) = gsub(\"(\\\\.txt$)||(\\\\.xml$)||(\\\\.html$)||(\\\\.htm$)\",                    \"\", rownames(table.with.all.freqs))                 colnames(distance.table) = gsub(\"(\\\\.txt$)||(\\\\.xml$)||(\\\\.html$)||(\\\\.htm$)\",                    \"\", rownames(table.with.all.freqs))             }             names.of.texts = gsub(\"(\\\\.txt)||(\\\\.xml)||(\\\\.html)||(\\\\.htm)\",                  \"\", rownames(table.with.all.freqs))             colors.of.pca.graph = assign.plot.colors(labels = names.of.texts,                  col = colors.on.graphs, opacity = 1)             name.of.the.method = \"\"             short.name.of.the.method = \"\"             mfw.info = mfw             plot.current.task = function() {                 NULL             }             if (start.at == 1) {                 start.at.info = \"\"             }             else {                 start.at.info = paste(\"Started at\", start.at)             }             if (delete.pronouns == TRUE) {                 pronouns.info = paste(\"Pronouns deleted\")             }             else {                 pronouns.info = \"\"             }             if (culling.min == culling.max) {                 culling.info = culling.min             }             else {                 culling.info = paste(culling.min, \"-\", culling.max,                    sep = \"\")             }             if (analysis.type == \"CA\") {                 name.of.the.method = \"Cluster Analysis\"                 short.name.of.the.method = \"CA\"                 if (dendrogram.layout.horizontal == TRUE) {                   dendrogram.margins = c(5, 4, 4, 8) + 0.1                 }                 else {                   dendrogram.margins = c(8, 5, 4, 4) + 0.1                 }                 plot.current.task = function() {                   par(mar = dendrogram.margins)                   if (linkage == \"nj\") {                     plot(nj(distance.table), font = 1, tip.color = colors.of.pca.graph)                   }                   else {                     clustered.data = hclust(as.dist(distance.table),                        method = linkage)                     colors.on.dendrogram = colors.of.pca.graph[clustered.data$order]                     tree.with.clusters = as.dendrogram(clustered.data,                        hang = 0)                     colLab = function(n) {                       if (is.leaf(n)) {                         a <- attributes(n)                         i <<- i + 1                         attr(n, \"nodePar\") <- c(a$nodePar, lab.col = mycols[i],                            pch = NA)                       }                       n                     }                     mycols = colors.on.dendrogram                     attributes(mycols) = NULL                     i = 0                     dendrogram.with.colors = dendrapply(tree.with.clusters,                        colLab)                     plot(dendrogram.with.colors, main = graph.main.title,                        horiz = dendrogram.layout.horizontal)                     if (dendrogram.layout.horizontal == TRUE) {                       title(sub = graph.subtitle)                     }                     else {                       title(sub = graph.subtitle, outer = TRUE,                          line = -1)                     }                   }                 }             }             if (analysis.type == \"MDS\") {                 name.of.the.method = \"Multidimensional Scaling\"                 distance.name.on.graph = \"\"                 distance.name.on.file = \"\"                 short.name.of.the.method = \"MDS\"                 mds.results = cmdscale(distance.table, eig = TRUE)                 xy.coord = mds.results$points[, 1:2]                 if (text.id.on.graphs == \"both\") {                   label.coord = cbind(mds.results$points[, 1],                      (mds.results$points[, 2] + (0.01 * label.offset *                        abs(max(mds.results$points[, 2]) - min(mds.results$points[,                          2])))))                 }                 else {                   label.coord = xy.coord                 }                 plot.area = define.plot.area(mds.results$points[,                    1], mds.results$points[, 2], xymargins = add.to.margins,                    v.offset = label.offset)                 plot.current.task = function() {                   if (text.id.on.graphs == \"points\" || text.id.on.graphs ==                      \"both\") {                     plot(xy.coord, type = \"p\", ylab = \"\", xlab = \"\",                        xlim = plot.area[[1]], ylim = plot.area[[2]],                        main = graph.main.title, sub = graph.subtitle,                        col = colors.of.pca.graph, lwd = plot.line.thickness)                   }                   if (text.id.on.graphs == \"labels\") {                     plot(xy.coord, type = \"n\", ylab = \"\", xlab = \"\",                        xlim = plot.area[[1]], ylim = plot.area[[2]],                        main = graph.main.title, sub = graph.subtitle,                        col = colors.of.pca.graph, lwd = plot.line.thickness)                   }                   if (text.id.on.graphs == \"labels\" || text.id.on.graphs ==                      \"both\") {                     text(label.coord, rownames(label.coord),                        col = colors.of.pca.graph)                   }                   axis(1, lwd = plot.line.thickness)                   axis(2, lwd = plot.line.thickness)                   box(lwd = plot.line.thickness)                 }             }             if (analysis.type == \"tSNE\") {                 name.of.the.method = \"t-Distributed Stochastic Neighbor Embedding\"                 short.name.of.the.method = \"t-SNE\"                 distance.name.on.file = \"tSNE\"                 distance.name.on.graph = \"t-SNE\"                 plot.current.task = function() {                   ecb = function(x, y) {                     if (titles.on.graphs == TRUE) {                       graph.main.title = paste(graph.title, \"\\nt-SNE visualisation\")                     }                     else {                       graph.main.title = \"\"                     }                     plot(x, t = \"n\", main = graph.main.title,                        xlab = \"\", ylab = \"\", yaxt = \"n\", xaxt = \"n\")                     text(x, rownames(table.with.all.freqs[, 1:mfw]),                        cex = 0.3)                   }                   tsne(X = table.with.all.freqs[, 1:mfw], initial_dims = 50,                      epoch_callback = ecb, perplexity = 50, max_iter = 2000)                 }             }             if (analysis.type == \"PCV\" || analysis.type == \"PCR\") {                 name.of.the.method = \"Principal Components Analysis\"                 short.name.of.the.method = \"PCA\"                 distance.name.on.file = \"PCA\"                 if (analysis.type == \"PCV\") {                   pca.results = prcomp(table.with.all.freqs[,                      1:mfw])                   distance.name.on.graph = \"Covariance matrix\"                 }                 else if (analysis.type == \"PCR\") {                   pca.results = prcomp(table.with.all.freqs[,                      1:mfw], scale = TRUE)                   distance.name.on.graph = \"Correlation matrix\"                 }                 expl.var = round(((pca.results$sdev^2)/sum(pca.results$sdev^2) *                    100), 1)                 PC1_lab = paste(\"PC1 (\", expl.var[1], \"%)\", sep = \"\")                 PC2_lab = paste(\"PC2 (\", expl.var[2], \"%)\", sep = \"\")                 xy.coord = pca.results$x[, 1:2]                 if (text.id.on.graphs == \"both\") {                   label.coord = cbind(pca.results$x[, 1], (pca.results$x[,                      2] + (0.01 * label.offset * abs(max(pca.results$x[,                      2]) - min(pca.results$x[, 2])))))                 }                 else {                   label.coord = xy.coord                 }                 plot.area = define.plot.area(pca.results$x[,                    1], pca.results$x[, 2], xymargins = add.to.margins,                    v.offset = label.offset)                 plot.current.task = function() {                   if (pca.visual.flavour == \"classic\") {                     if (text.id.on.graphs == \"points\" || text.id.on.graphs ==                        \"both\") {                       plot(xy.coord, type = \"p\", xlim = plot.area[[1]],                          ylim = plot.area[[2]], xlab = \"\", ylab = PC2_lab,                          main = graph.main.title, sub = paste(PC1_lab,                            \"\\n\", graph.subtitle), col = colors.of.pca.graph,                          lwd = plot.line.thickness)                     }                     if (text.id.on.graphs == \"labels\") {                       plot(xy.coord, type = \"n\", xlim = plot.area[[1]],                          ylim = plot.area[[2]], xlab = \"\", ylab = PC2_lab,                          main = graph.main.title, sub = paste(PC1_lab,                            \"\\n\", graph.subtitle), col = colors.of.pca.graph,                          lwd = plot.line.thickness)                     }                     abline(h = 0, v = 0, col = \"gray60\", lty = 2)                     if (text.id.on.graphs == \"labels\" || text.id.on.graphs ==                        \"both\") {                       text(label.coord, rownames(pca.results$x),                          col = colors.of.pca.graph)                     }                     axis(1, lwd = plot.line.thickness)                     axis(2, lwd = plot.line.thickness)                     box(lwd = plot.line.thickness)                   }                   else if (pca.visual.flavour == \"loadings\") {                     biplot(pca.results, col = c(\"grey70\", \"black\"),                        cex = c(0.7, 1), xlab = \"\", ylab = PC2_lab,                        main = paste(graph.main.title, \"\\n\\n\",                          sep = \"\"), sub = paste(PC1_lab, \"\\n\",                          graph.subtitle, sep = \"\"), var.axes = FALSE)                   }                   else if (pca.visual.flavour == \"technical\") {                     layout(matrix(c(1, 2), 2, 2, byrow = TRUE),                        widths = c(3, 1))                     biplot(pca.results, col = c(\"black\", \"grey40\"),                        cex = c(1, 0.9), xlab = \"\", ylab = PC2_lab,                        main = paste(graph.main.title, \"\\n\\n\",                          sep = \"\"), sub = paste(PC1_lab, \"\\n\",                          graph.subtitle, sep = \"\"), var.axes = FALSE)                     abline(h = 0, v = 0, col = \"gray60\", lty = 3)                     row = mat.or.vec(nc = ncol(pca.results$x),                        nr = 1)                     for (i in 1:ncol(row)) {                       row[, i] <- \"grey45\"                     }                     row[, 1] <- \"black\"                     row[, 2] <- \"black\"                     barplot(expl.var, col = row, xlab = \"Principal components\",                        ylab = \"Proportion of variance explained (in %)\")                     abline(h = 5, lty = 3)                   }                   else if (pca.visual.flavour == \"symbols\") {                     labels = c()                     for (c in rownames(pca.results$x)) {                       labels = c(labels, gsub(\"_.*\", \"\", c))                     }                     COOR = data.frame(pca.results$x[, 1:2], LABEL = labels)                     labels <- c(levels(COOR$LABEL))                     sps <- trellis.par.get(\"superpose.symbol\")                     sps$pch <- 1:length(labels)                     trellis.par.set(\"superpose.symbol\", sps)                     ltheme <- canonical.theme(color = FALSE)                     lattice.options(default.theme = ltheme)                     pl <- xyplot(data = COOR, x = PC2 ~ PC1,                        xlab = paste(PC1_lab, \"\\n\", graph.subtitle,                          sep = \"\"), ylab = PC2_lab, groups = COOR$LABEL,                        sub = \"\", key = list(columns = 2, text = list(labels),                          points = Rows(sps, 1:length(labels))),                        panel = function(x, ...) {                         panel.xyplot(x, ...)                         panel.abline(v = 0, lty = 3)                         panel.abline(h = 0, lty = 3)                       })                     plot(pl)                   }                 }             }             if (analysis.type == \"BCT\") {                 mfw.info = paste(mfw.min, \"-\", mfw.info, sep = \"\")                 name.of.the.method = \"Bootstrap Consensus Tree\"                 short.name.of.the.method = \"Consensus\"                 if (linkage == \"nj\") {                   current.bootstrap.results = nj(as.dist(distance.table))                 }                 else {                   current.bootstrap.results = as.phylo(hclust(as.dist(distance.table),                      method = linkage))                 }                 bootstrap.list[[number.of.current.iteration]] = current.bootstrap.results             }             if (ngram.size > 1) {                 ngram.value = paste(ngram.size, \"-grams\", sep = \"\")             }             else {                 ngram.value = \"\"             }             if (titles.on.graphs == TRUE) {                 graph.main.title = paste(graph.title, \"\\n\", name.of.the.method)                 if (analysis.type == \"BCT\") {                   graph.subtitle = paste(mfw.info, \" MF\", toupper(analyzed.features),                      \" \", ngram.value, \" Culled @ \", culling.info,                      \"%\\n\", pronouns.info, \" \", distance.name.on.graph,                      \" Consensus \", consensus.strength, \" \", start.at.info,                      sep = \"\")                 }                 else {                   graph.subtitle = paste(mfw.info, \" MF\", toupper(analyzed.features),                      \" \", ngram.value, \" Culled @ \", culling.info,                      \"%\\n\", pronouns.info, \" \", distance.name.on.graph,                      \" \", start.at.info, sep = \"\")                 }             }             else {                 graph.main.title = \"\"                 graph.subtitle = \"\"             }             if (is.character(custom.graph.filename) == TRUE &                  length(custom.graph.filename) > 0) {                 graph.filename = custom.graph.filename             }             else {                 if (analysis.type == \"BCT\") {                   graph.filename = paste(basename(getwd()), short.name.of.the.method,                      mfw.info, \"MFWs_Culled\", culling.info, pronouns.info,                      distance.name.on.file, \"C\", consensus.strength,                      start.at.info, sep = \"_\")                 }                 else {                   graph.filename = paste(basename(getwd()), short.name.of.the.method,                      mfw.info, \"MFWs_Culled\", culling.info, pronouns.info,                      distance.name.on.file, start.at.info, sep = \"_\")                 }             }             if (analysis.type != \"BCT\") {                 if (display.on.screen == TRUE) {                   plot.current.task()                 }                 if (write.pdf.file == TRUE) {                   pdf(file = paste(graph.filename, \"_%03d\", \".pdf\",                      sep = \"\"), width = plot.custom.width, height = plot.custom.height,                      pointsize = plot.font.size)                   plot.current.task()                   dev.off()                 }                 if (write.jpg.file == TRUE) {                   jpeg(filename = paste(graph.filename, \"_%03d\",                      \".jpg\", sep = \"\"), width = plot.custom.width,                      height = plot.custom.height, units = \"in\",                      res = 300, pointsize = plot.font.size)                   plot.current.task()                   dev.off()                 }                 if (write.svg.file == TRUE) {                   svg(filename = paste(graph.filename, \"_%03d\",                      \".svg\", sep = \"\"), width = plot.custom.width,                      height = plot.custom.height, pointsize = plot.font.size)                   plot.current.task()                   dev.off()                 }                 if (write.png.file == TRUE) {                   png(filename = paste(graph.filename, \"_%03d\",                      \".png\", sep = \"\"), width = plot.custom.width,                      height = plot.custom.height, units = \"in\",                      res = 300, pointsize = plot.font.size)                   plot.current.task()                   dev.off()                 }             }             if (save.distance.tables == TRUE && exists(\"distance.table\") ==                  TRUE) {                 distance.table.filename = paste(\"distance_table_\",                    mfw, \"mfw_\", current.culling, \"c.txt\", sep = \"\")                 if (encoding == \"native.enc\") {                   data.to.be.saved = distance.table                 }                 else {                   data.to.be.saved = distance.table                   rownames(data.to.be.saved) = iconv(rownames(data.to.be.saved),                      to = encoding)                   colnames(data.to.be.saved) = iconv(colnames(data.to.be.saved),                      to = encoding)                 }                 write.table(file = distance.table.filename, data.to.be.saved)             }             features.actually.used = colnames(table.with.all.freqs[,                  1:mfw])             if (save.analyzed.features == TRUE) {                 if (encoding == \"native.enc\") {                   data.to.be.saved = features.actually.used                 }                 else {                   data.to.be.saved = iconv(features.actually.used,                      to = encoding)                 }                 cat(data.to.be.saved, file = paste(\"features_analyzed_\",                    mfw, \"mfw_\", current.culling, \"c.txt\", sep = \"\"),                    sep = \"\\n\")             }             if (save.analyzed.freqs == TRUE) {                 if (encoding == \"native.enc\") {                   data.to.be.saved = t(table.with.all.freqs[,                      1:mfw])                 }                 else {                   data.to.be.saved = t(table.with.all.freqs[,                      1:mfw])                   rownames(data.to.be.saved) = iconv(rownames(data.to.be.saved),                      to = encoding)                   colnames(data.to.be.saved) = iconv(colnames(data.to.be.saved),                      to = encoding)                 }                 write.table(data.to.be.saved, file = paste(\"frequencies_analyzed_\",                    mfw, \"mfw_\", current.culling, \"c.txt\", sep = \"\"))             }             if ((exists(\"distance.table\") == TRUE) & (network ==                  TRUE)) {                 distances = distance.table                 connections = matrix(data = 0, nrow = length(distances[,                    1]), ncol = length(distances[1, ]))                 for (i in 1:length(distances[, 1])) {                   for (k in 1:linked.neighbors) {                     connections[i, (order(distances[i, ])[k +                        1])] = linked.neighbors - k + 1                   }                 }                 if (edge.weights == \"quadratic\") {                   connections = connections^2                 }                 else if (edge.weights == \"log\") {                   connections = log(connections + 1)                 }                 all.connections = all.connections + connections             }         }         cat(\"\\n\")     }     if ((exists(\"distance.table\") == TRUE) & (network == TRUE)) {         rownames(all.connections) = rownames(distances)         colnames(all.connections) = colnames(distances)         if (network.tables == \"edges\") {             edges = c()             for (i in 1:(length(all.connections[, 1]))) {                 for (j in 1:(length(all.connections[1, ]))) {                   from = rownames(all.connections)[i]                   to = colnames(all.connections)[j]                   if (network.type == \"undirected\") {                     weight = all.connections[i, j] + all.connections[j,                        i]                     current.row = c(from, to, weight, \"undirected\")                   }                   else {                     weight = all.connections[i, j]                     current.row = c(from, to, weight, \"directed\")                   }                   if (weight > 0) {                     edges = rbind(edges, current.row)                   }                 }             }             colnames(edges) = c(\"Source\", \"Target\", \"Weight\",                  \"Type\")             rownames(edges) = c(1:length(edges[, 1]))             edges = as.data.frame(edges)             edges.filename = paste(graph.filename, \"EDGES.csv\",                  sep = \"\")             write.csv(file = edges.filename, quote = F, edges)         }         else {             edges = c()             for (i in 1:(length(all.connections[, 1]))) {                 for (j in 1:(length(all.connections[1, ]))) {                   from = c(1:length(rownames(all.connections)))[i]                   to = c(1:length(colnames(all.connections)))[j]                   if (network.type == \"undirected\") {                     weight = all.connections[i, j] + all.connections[j,                        i]                     current.row = c(from - 1, to - 1, weight,                        \"undirected\")                   }                   else {                     weight = all.connections[i, j]                     current.row = c(from - 1, to - 1, weight,                        \"directed\")                   }                   if (weight > 0) {                     edges = rbind(edges, current.row)                   }                 }             }             colnames(edges) = c(\"Source\", \"Target\", \"Weight\",                  \"Type\")             rownames(edges) = c(1:length(edges[, 1]))             edges = as.data.frame(edges, stringsAsFactors = FALSE)             node.id = c(1:length(rownames(all.connections))) -                  1             node.names = rownames(all.connections)             node.classes = gsub(\"_.*\", \"\", node.names)             node.classes.numeric = as.numeric(factor(gsub(\"_.*\",                  \"\", node.names)))             nodes = cbind(node.id, node.names, node.classes,                  node.classes.numeric)             colnames(nodes) = c(\"Id\", \"Label\", \"Classes\", \"Group\")             nodes = as.data.frame(nodes, stringsAsFactors = FALSE)             edges.filename = paste(graph.filename, \"EDGES.csv\",                  sep = \"\")             write.csv(file = edges.filename, quote = F, edges)             nodes.filename = paste(graph.filename, \"NODES.csv\",                  sep = \"\")             write.csv(file = nodes.filename, quote = F, nodes)         }     }     if (length(all.connections) == 1) {         rm(all.connections)     }     if (analysis.type == \"BCT\") {         if (length(bootstrap.list) <= 2) {             cat(\"\\n\\nSORRY, BUT YOU ARE EXPECTING TOO MUCH...!\\n\\n\",                  \"There should be at least 3 iterations to make a consensus tree\\n\\n\")         }         else {             plot.current.task = function() {                 plot(consensus(bootstrap.list, p = consensus.strength),                    type = \"u\", font = 1, lab4ut = \"axial\", tip.color = colors.of.pca.graph)                 title(main = graph.main.title)                 title(sub = graph.subtitle)             }             if (display.on.screen == TRUE) {                 plot.current.task()             }             if (write.pdf.file == TRUE) {                 pdf(file = paste(graph.filename, \"_%03d\", \".pdf\",                    sep = \"\"), width = plot.custom.width, height = plot.custom.height,                    pointsize = plot.font.size)                 plot.current.task()                 dev.off()             }             if (write.jpg.file == TRUE) {                 jpeg(filename = paste(graph.filename, \"_%03d\",                    \".jpg\", sep = \"\"), width = plot.custom.width,                    height = plot.custom.height, units = \"in\",                    res = 300, pointsize = plot.font.size)                 plot.current.task()                 dev.off()             }             if (write.svg.file == TRUE) {                 svg(filename = paste(graph.filename, \"_%03d\",                    \".svg\", sep = \"\"), width = plot.custom.width,                    height = plot.custom.height, pointsize = plot.font.size)                 plot.current.task()                 dev.off()             }             if (write.png.file == TRUE) {                 png(filename = paste(graph.filename, \"_%03d\",                    \".png\", sep = \"\"), width = plot.custom.width,                    height = plot.custom.height, units = \"in\",                    res = 300, pointsize = plot.font.size)                 plot.current.task()                 dev.off()             }         }     }     features = mfw.list.of.all     if (exists(\"pca.results\") == TRUE) {         pca.coordinates = pca.results$x         pca.rotation = pca.results$rotation         pca.sdev = pca.results$sdev         pca.var.exp = round((pca.results$sdev^2)/sum(pca.results$sdev^2) *              100, 2)     }     if (exists(\"all.connections\") == TRUE) {         table.edges = all.connections     }     if (exists(\"edges\") == TRUE & length(edges) > 1) {         list.of.edges = edges     }     if (exists(\"nodes\") == TRUE) {         list.of.nodes = nodes     }     if (exists(\"distance.table\")) {         attr(distance.table, \"description\") = \"final distances between each pair of samples\"         class(distance.table) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"frequencies.0.culling\")) {         attr(frequencies.0.culling, \"description\") = \"frequencies of words/features accross the corpus\"         class(frequencies.0.culling) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"table.with.all.freqs\")) {         attr(table.with.all.freqs, \"description\") = \"frequencies of words/features accross the corpus\"         class(table.with.all.freqs) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"table.with.all.zscores\")) {         attr(table.with.all.zscores, \"description\") = \"z-scored frequencies accross the corpus\"         class(table.with.all.zscores) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"features\")) {         attr(features, \"description\") = \"features (e.g. words, n-grams, ...) applied to data\"         class(features) = \"stylo.data\"     }     if (exists(\"features.actually.used\")) {         attr(features.actually.used, \"description\") = \"features (e.g. frequent words) actually analyzed\"         class(features.actually.used) = \"stylo.data\"     }     if (exists(\"table.of.edges\")) {         attr(table.of.edges, \"description\") = \"edges of a network of stylometric similarities\"     }     if (exists(\"list.of.edges\")) {         attr(list.of.edges, \"description\") = \"edges of a network of stylometric similarities\"     }     if (exists(\"list.of.nodes\")) {         attr(list.of.nodes, \"description\") = \"nodes of a network of stylometric similarities\"     }     if (exists(\"pca.coordinates\")) {         attr(pca.coordinates, \"description\") = \"PCA matrix of coordinates for particular PCs\"         class(pca.coordinates) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"pca.rotation\")) {         attr(pca.rotation, \"description\") = \"PCA matrix of variable loadings' eigenvectors\"         class(pca.rotation) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"pca.sdev\")) {         attr(pca.sdev, \"description\") = \"PCA: standard deviations or particular PCs\"         class(pca.sdev) = c(\"stylo.data\", \"matrix\")     }     if (exists(\"pca.var.exp\")) {         attr(pca.var.exp, \"description\") = \"PCA: explained variance [%] for particular PCs\"         class(pca.var.exp) = c(\"stylo.data\", \"matrix\")     }     results.stylo = list()     variables.to.save = c(\"distance.table\", \"frequencies.0.culling\",          \"table.with.all.freqs\", \"table.with.all.zscores\", \"features\",          \"features.actually.used\", \"pca.coordinates\", \"pca.rotation\",          \"pca.sdev\", \"pca.var.exp\", \"table.of.edges\", \"list.of.edges\",          \"list.of.nodes\")     filtered.variables = ls()[ls() %in% variables.to.save]     for (i in filtered.variables) {         results.stylo[[i]] = get(i)     }     results.stylo$call = match.call()     results.stylo$name = call(\"stylo\")     class(results.stylo) <- \"stylo.results\"     setwd(original.path)     return(results.stylo) })(gui = \"F\", distance.measure = \"dist.eder\", sampling = \"no.sampling\",      write.png.file = TRUE, analyzed.features = \"w\", save.analyzed.freqs = TRUE,      mfw.list.cutoff = 5000L, display.on.screen = FALSE, save.distance.tables = TRUE,      ngram.size = 1L, analysis.type = \"CA\", mfw.max = 5000L, preserve.case = FALSE,      save.analyzed.features = TRUE, mfw.min = 5000L) \n",
      "\n",
      "Depending on your chosen options, some results should have been written\n",
      "into a few files; you should be able to find them in your current\n",
      "(working) directory. Usually, these include a list of words/features\n",
      "used to build a table of frequencies, the table itself, a file containing\n",
      "recent configuration, etc.\n",
      "\n",
      "Advanced users: you can pipe the results to a variable, e.g.:\n",
      "\t hip.hip.hurrah = stylo() \n",
      "this will create a class \"hip.hip.hurrah\" containing some presumably\n",
      "interesting stuff. The class created, you can type, e.g.:\n",
      "\t summary(hip.hip.hurrah)\n",
      "to see which variables are stored there and how to use them.\n",
      "\n",
      "\n",
      "for suggestions how to cite this software, type: citation(\"stylo\")\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(I_love_this_stuff))\n",
    "print(len(I_love_this_stuff))\n",
    "print(I_love_this_stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, my data variable is a List of Vector of length 9. Each of these items contain different information from the analysis I have done. For example, the first item contains actually the distance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rpy2.robjects.vectors.Matrix'>\n",
      "\n",
      "--------------------------------------------\n",
      "final distances between each pair of samples \n",
      "--------------------------------------------\n",
      "\n",
      "                            Bazan_Pazos-ne0077 Bazan_Piedra-ne0082\n",
      "Bazan_Pazos-ne0077          0                  1888.5245394       \n",
      "Bazan_Piedra-ne0082         1888.5245394       0                  \n",
      "Bazan_Sirena-ne0085         2133.6560362       2101.6861626       \n",
      "BlascoIbanez_Arroz-ne0163   2261.4495052       2413.2292456       \n",
      "BlascoIbanez_Barraca-ne0164 2485.5174716       2618.0304242       \n",
      "BlascoIbanez_Bodega-ne0019  2292.5467693       2411.1421787       \n",
      "Clarin_Cuesta-ne0170        2833.7510012       2788.7184217       \n",
      "Clarin_Hijo-ne0135          2255.7227789       2371.0966337       \n",
      "Clarin_Regenta-ne0325       2107.9031058       2301.6654136       \n",
      "Galdos_Bringas-ne0027       2165.8468701       2303.483447        \n",
      "                            ...                ...                \n",
      "                            Bazan_Sirena-ne0085 BlascoIbanez_Arroz-ne0163\n",
      "Bazan_Pazos-ne0077          2133.6560362        2261.4495052             \n",
      "Bazan_Piedra-ne0082         2101.6861626        2413.2292456             \n",
      "Bazan_Sirena-ne0085         0                   2574.0800621             \n",
      "BlascoIbanez_Arroz-ne0163   2574.0800621        0                        \n",
      "BlascoIbanez_Barraca-ne0164 2869.2693571        2140.1683433             \n",
      "BlascoIbanez_Bodega-ne0019  2603.6117516        1923.1974534             \n",
      "Clarin_Cuesta-ne0170        2694.8682498        2955.4067595             \n",
      "Clarin_Hijo-ne0135          2494.7496826        2380.7170764             \n",
      "Clarin_Regenta-ne0325       2469.0595925        2307.240663              \n",
      "Galdos_Bringas-ne0027       2422.7274176        2367.1461745             \n",
      "                            ...                 ...                      \n",
      "                            BlascoIbanez_Barraca-ne0164\n",
      "Bazan_Pazos-ne0077          2485.5174716               \n",
      "Bazan_Piedra-ne0082         2618.0304242               \n",
      "Bazan_Sirena-ne0085         2869.2693571               \n",
      "BlascoIbanez_Arroz-ne0163   2140.1683433               \n",
      "BlascoIbanez_Barraca-ne0164 0                          \n",
      "BlascoIbanez_Bodega-ne0019  2087.0814921               \n",
      "Clarin_Cuesta-ne0170        3183.5231315               \n",
      "Clarin_Hijo-ne0135          2753.838045                \n",
      "Clarin_Regenta-ne0325       2679.9233289               \n",
      "Galdos_Bringas-ne0027       2780.0747673               \n",
      "                            ...                        \n",
      "                            BlascoIbanez_Bodega-ne0019 Clarin_Cuesta-ne0170\n",
      "Bazan_Pazos-ne0077          2292.5467693               2833.7510012        \n",
      "Bazan_Piedra-ne0082         2411.1421787               2788.7184217        \n",
      "Bazan_Sirena-ne0085         2603.6117516               2694.8682498        \n",
      "BlascoIbanez_Arroz-ne0163   1923.1974534               2955.4067595        \n",
      "BlascoIbanez_Barraca-ne0164 2087.0814921               3183.5231315        \n",
      "BlascoIbanez_Bodega-ne0019  0                          2951.3627689        \n",
      "Clarin_Cuesta-ne0170        2951.3627689               0                   \n",
      "Clarin_Hijo-ne0135          2460.7589145               2599.7408745        \n",
      "Clarin_Regenta-ne0325       2381.0569938               2704.2315017        \n",
      "Galdos_Bringas-ne0027       2545.8382723               2874.8763377        \n",
      "                            ...                        ...                 \n",
      "                            Clarin_Hijo-ne0135 Clarin_Regenta-ne0325\n",
      "Bazan_Pazos-ne0077          2255.7227789       2107.9031058         \n",
      "Bazan_Piedra-ne0082         2371.0966337       2301.6654136         \n",
      "Bazan_Sirena-ne0085         2494.7496826       2469.0595925         \n",
      "BlascoIbanez_Arroz-ne0163   2380.7170764       2307.240663          \n",
      "BlascoIbanez_Barraca-ne0164 2753.838045        2679.9233289         \n",
      "BlascoIbanez_Bodega-ne0019  2460.7589145       2381.0569938         \n",
      "Clarin_Cuesta-ne0170        2599.7408745       2704.2315017         \n",
      "Clarin_Hijo-ne0135          0                  1752.0545972         \n",
      "Clarin_Regenta-ne0325       1752.0545972       0                    \n",
      "Galdos_Bringas-ne0027       2291.4156091       2287.2948095         \n",
      "                            ...                ...                  \n",
      "                            Galdos_Bringas-ne0027 Galdos_Misericordia-ne0002\n",
      "Bazan_Pazos-ne0077          2165.8468701          2096.9659862              \n",
      "Bazan_Piedra-ne0082         2303.483447           2197.2898637              \n",
      "Bazan_Sirena-ne0085         2422.7274176          2354.063441               \n",
      "BlascoIbanez_Arroz-ne0163   2367.1461745          2427.3454209              \n",
      "BlascoIbanez_Barraca-ne0164 2780.0747673          2756.0839675              \n",
      "BlascoIbanez_Bodega-ne0019  2545.8382723          2474.6716211              \n",
      "Clarin_Cuesta-ne0170        2874.8763377          2891.2306426              \n",
      "Clarin_Hijo-ne0135          2291.4156091          2402.1424844              \n",
      "Clarin_Regenta-ne0325       2287.2948095          2349.4291862              \n",
      "Galdos_Bringas-ne0027       0                     1910.3801821              \n",
      "                            ...                   ...                       \n",
      "                               \n",
      "Bazan_Pazos-ne0077          ...\n",
      "Bazan_Piedra-ne0082         ...\n",
      "Bazan_Sirena-ne0085         ...\n",
      "BlascoIbanez_Arroz-ne0163   ...\n",
      "BlascoIbanez_Barraca-ne0164 ...\n",
      "BlascoIbanez_Bodega-ne0019  ...\n",
      "Clarin_Cuesta-ne0170        ...\n",
      "Clarin_Hijo-ne0135          ...\n",
      "Clarin_Regenta-ne0325       ...\n",
      "Galdos_Bringas-ne0027       ...\n",
      "                            ...\n",
      "\n",
      "(total number of rows/columns:  24/24)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(I_love_this_stuff[0]))\n",
    "print(I_love_this_stuff[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, this object is a matrix in R. Working in Python we would be happier with a Pandas Dataframe. For doing that, we convert first the matrix in a Numpy array, we use this array to load I_love_this_stuff to the dataframe, and we pass the names of the rows and the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bazan_Pazos-ne0077</th>\n",
       "      <th>Bazan_Piedra-ne0082</th>\n",
       "      <th>Bazan_Sirena-ne0085</th>\n",
       "      <th>BlascoIbanez_Arroz-ne0163</th>\n",
       "      <th>BlascoIbanez_Barraca-ne0164</th>\n",
       "      <th>BlascoIbanez_Bodega-ne0019</th>\n",
       "      <th>Clarin_Cuesta-ne0170</th>\n",
       "      <th>Clarin_Hijo-ne0135</th>\n",
       "      <th>Clarin_Regenta-ne0325</th>\n",
       "      <th>Galdos_Bringas-ne0027</th>\n",
       "      <th>...</th>\n",
       "      <th>Miro_Vivir-ne0042</th>\n",
       "      <th>Pereda_Pedro-ne0144</th>\n",
       "      <th>Pereda_Penas-ne0145</th>\n",
       "      <th>Pereda_Sotileza-ne0146</th>\n",
       "      <th>Picon_Dulce-ne0155</th>\n",
       "      <th>Picon_JuanV-ne0162</th>\n",
       "      <th>Picon_Lazaro-ne0161</th>\n",
       "      <th>Valera_Genio-ne0151</th>\n",
       "      <th>Valera_Juanita-ne0152</th>\n",
       "      <th>Valera_Morsamor-ne0153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bazan_Pazos-ne0077</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1888.524539</td>\n",
       "      <td>2133.656036</td>\n",
       "      <td>2261.449505</td>\n",
       "      <td>2485.517472</td>\n",
       "      <td>2292.546769</td>\n",
       "      <td>2833.751001</td>\n",
       "      <td>2255.722779</td>\n",
       "      <td>2107.903106</td>\n",
       "      <td>2165.846870</td>\n",
       "      <td>...</td>\n",
       "      <td>2692.634044</td>\n",
       "      <td>2129.738339</td>\n",
       "      <td>2052.474196</td>\n",
       "      <td>2097.021096</td>\n",
       "      <td>2181.173081</td>\n",
       "      <td>2537.517957</td>\n",
       "      <td>2568.952628</td>\n",
       "      <td>2467.284030</td>\n",
       "      <td>2152.521632</td>\n",
       "      <td>2373.088271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bazan_Piedra-ne0082</th>\n",
       "      <td>1888.524539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2101.686163</td>\n",
       "      <td>2413.229246</td>\n",
       "      <td>2618.030424</td>\n",
       "      <td>2411.142179</td>\n",
       "      <td>2788.718422</td>\n",
       "      <td>2371.096634</td>\n",
       "      <td>2301.665414</td>\n",
       "      <td>2303.483447</td>\n",
       "      <td>...</td>\n",
       "      <td>2714.389804</td>\n",
       "      <td>2208.201252</td>\n",
       "      <td>2213.707590</td>\n",
       "      <td>2159.672964</td>\n",
       "      <td>2274.322568</td>\n",
       "      <td>2560.370894</td>\n",
       "      <td>2618.898680</td>\n",
       "      <td>2504.649140</td>\n",
       "      <td>2284.564593</td>\n",
       "      <td>2391.257775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bazan_Sirena-ne0085</th>\n",
       "      <td>2133.656036</td>\n",
       "      <td>2101.686163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2574.080062</td>\n",
       "      <td>2869.269357</td>\n",
       "      <td>2603.611752</td>\n",
       "      <td>2694.868250</td>\n",
       "      <td>2494.749683</td>\n",
       "      <td>2469.059592</td>\n",
       "      <td>2422.727418</td>\n",
       "      <td>...</td>\n",
       "      <td>2842.195431</td>\n",
       "      <td>2324.406443</td>\n",
       "      <td>2349.662223</td>\n",
       "      <td>2439.833464</td>\n",
       "      <td>2333.246418</td>\n",
       "      <td>2699.575492</td>\n",
       "      <td>2661.347957</td>\n",
       "      <td>2502.916654</td>\n",
       "      <td>2430.757873</td>\n",
       "      <td>2510.821798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlascoIbanez_Arroz-ne0163</th>\n",
       "      <td>2261.449505</td>\n",
       "      <td>2413.229246</td>\n",
       "      <td>2574.080062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2140.168343</td>\n",
       "      <td>1923.197453</td>\n",
       "      <td>2955.406759</td>\n",
       "      <td>2380.717076</td>\n",
       "      <td>2307.240663</td>\n",
       "      <td>2367.146174</td>\n",
       "      <td>...</td>\n",
       "      <td>2848.758451</td>\n",
       "      <td>2364.020159</td>\n",
       "      <td>2376.773223</td>\n",
       "      <td>2445.424526</td>\n",
       "      <td>2445.485729</td>\n",
       "      <td>2597.534945</td>\n",
       "      <td>2617.380280</td>\n",
       "      <td>2644.515895</td>\n",
       "      <td>2452.854914</td>\n",
       "      <td>2589.977293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlascoIbanez_Barraca-ne0164</th>\n",
       "      <td>2485.517472</td>\n",
       "      <td>2618.030424</td>\n",
       "      <td>2869.269357</td>\n",
       "      <td>2140.168343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2087.081492</td>\n",
       "      <td>3183.523131</td>\n",
       "      <td>2753.838045</td>\n",
       "      <td>2679.923329</td>\n",
       "      <td>2780.074767</td>\n",
       "      <td>...</td>\n",
       "      <td>2778.458402</td>\n",
       "      <td>2728.936723</td>\n",
       "      <td>2569.968181</td>\n",
       "      <td>2670.966947</td>\n",
       "      <td>2870.449013</td>\n",
       "      <td>2991.170549</td>\n",
       "      <td>2845.063189</td>\n",
       "      <td>2963.664838</td>\n",
       "      <td>2751.053181</td>\n",
       "      <td>2785.147995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlascoIbanez_Bodega-ne0019</th>\n",
       "      <td>2292.546769</td>\n",
       "      <td>2411.142179</td>\n",
       "      <td>2603.611752</td>\n",
       "      <td>1923.197453</td>\n",
       "      <td>2087.081492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2951.362769</td>\n",
       "      <td>2460.758914</td>\n",
       "      <td>2381.056994</td>\n",
       "      <td>2545.838272</td>\n",
       "      <td>...</td>\n",
       "      <td>2761.898703</td>\n",
       "      <td>2399.087185</td>\n",
       "      <td>2362.920219</td>\n",
       "      <td>2485.379047</td>\n",
       "      <td>2590.448137</td>\n",
       "      <td>2714.085476</td>\n",
       "      <td>2660.198587</td>\n",
       "      <td>2677.056816</td>\n",
       "      <td>2477.597820</td>\n",
       "      <td>2500.963617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarin_Cuesta-ne0170</th>\n",
       "      <td>2833.751001</td>\n",
       "      <td>2788.718422</td>\n",
       "      <td>2694.868250</td>\n",
       "      <td>2955.406759</td>\n",
       "      <td>3183.523131</td>\n",
       "      <td>2951.362769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2599.740875</td>\n",
       "      <td>2704.231502</td>\n",
       "      <td>2874.876338</td>\n",
       "      <td>...</td>\n",
       "      <td>3116.691359</td>\n",
       "      <td>2709.556446</td>\n",
       "      <td>2700.670607</td>\n",
       "      <td>2898.486426</td>\n",
       "      <td>2911.209593</td>\n",
       "      <td>3001.134998</td>\n",
       "      <td>2979.386879</td>\n",
       "      <td>2779.595212</td>\n",
       "      <td>2799.188649</td>\n",
       "      <td>2840.853888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarin_Hijo-ne0135</th>\n",
       "      <td>2255.722779</td>\n",
       "      <td>2371.096634</td>\n",
       "      <td>2494.749683</td>\n",
       "      <td>2380.717076</td>\n",
       "      <td>2753.838045</td>\n",
       "      <td>2460.758914</td>\n",
       "      <td>2599.740875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1752.054597</td>\n",
       "      <td>2291.415609</td>\n",
       "      <td>...</td>\n",
       "      <td>3046.434380</td>\n",
       "      <td>2247.974230</td>\n",
       "      <td>2264.813618</td>\n",
       "      <td>2397.839703</td>\n",
       "      <td>2282.923914</td>\n",
       "      <td>2548.352462</td>\n",
       "      <td>2607.618169</td>\n",
       "      <td>2384.867753</td>\n",
       "      <td>2252.733794</td>\n",
       "      <td>2451.050301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarin_Regenta-ne0325</th>\n",
       "      <td>2107.903106</td>\n",
       "      <td>2301.665414</td>\n",
       "      <td>2469.059592</td>\n",
       "      <td>2307.240663</td>\n",
       "      <td>2679.923329</td>\n",
       "      <td>2381.056994</td>\n",
       "      <td>2704.231502</td>\n",
       "      <td>1752.054597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2287.294810</td>\n",
       "      <td>...</td>\n",
       "      <td>2944.264941</td>\n",
       "      <td>2241.958666</td>\n",
       "      <td>2283.567180</td>\n",
       "      <td>2366.994209</td>\n",
       "      <td>2309.467804</td>\n",
       "      <td>2633.959138</td>\n",
       "      <td>2607.336197</td>\n",
       "      <td>2513.086162</td>\n",
       "      <td>2264.576739</td>\n",
       "      <td>2522.379293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galdos_Bringas-ne0027</th>\n",
       "      <td>2165.846870</td>\n",
       "      <td>2303.483447</td>\n",
       "      <td>2422.727418</td>\n",
       "      <td>2367.146174</td>\n",
       "      <td>2780.074767</td>\n",
       "      <td>2545.838272</td>\n",
       "      <td>2874.876338</td>\n",
       "      <td>2291.415609</td>\n",
       "      <td>2287.294810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2979.822925</td>\n",
       "      <td>2150.504746</td>\n",
       "      <td>2142.769529</td>\n",
       "      <td>2224.926537</td>\n",
       "      <td>2263.362507</td>\n",
       "      <td>2505.718200</td>\n",
       "      <td>2689.517108</td>\n",
       "      <td>2457.253401</td>\n",
       "      <td>2186.799020</td>\n",
       "      <td>2516.545984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galdos_Misericordia-ne0002</th>\n",
       "      <td>2096.965986</td>\n",
       "      <td>2197.289864</td>\n",
       "      <td>2354.063441</td>\n",
       "      <td>2427.345421</td>\n",
       "      <td>2756.083968</td>\n",
       "      <td>2474.671621</td>\n",
       "      <td>2891.230643</td>\n",
       "      <td>2402.142484</td>\n",
       "      <td>2349.429186</td>\n",
       "      <td>1910.380182</td>\n",
       "      <td>...</td>\n",
       "      <td>2872.583415</td>\n",
       "      <td>2206.613315</td>\n",
       "      <td>2143.877946</td>\n",
       "      <td>2118.256240</td>\n",
       "      <td>2128.506321</td>\n",
       "      <td>2547.426760</td>\n",
       "      <td>2800.377069</td>\n",
       "      <td>2528.349219</td>\n",
       "      <td>2184.957919</td>\n",
       "      <td>2497.194151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galdos_Tristana-ne0005</th>\n",
       "      <td>2308.957339</td>\n",
       "      <td>2303.044233</td>\n",
       "      <td>2322.562916</td>\n",
       "      <td>2554.253675</td>\n",
       "      <td>2951.060462</td>\n",
       "      <td>2628.540593</td>\n",
       "      <td>2760.622010</td>\n",
       "      <td>2367.034402</td>\n",
       "      <td>2432.886012</td>\n",
       "      <td>2113.927698</td>\n",
       "      <td>...</td>\n",
       "      <td>3027.095203</td>\n",
       "      <td>2266.909252</td>\n",
       "      <td>2308.811201</td>\n",
       "      <td>2342.655215</td>\n",
       "      <td>2225.311701</td>\n",
       "      <td>2566.157941</td>\n",
       "      <td>2714.227547</td>\n",
       "      <td>2368.039339</td>\n",
       "      <td>2272.183304</td>\n",
       "      <td>2517.350645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miro_Amigo-ne0044</th>\n",
       "      <td>2833.990414</td>\n",
       "      <td>2787.848589</td>\n",
       "      <td>2708.059847</td>\n",
       "      <td>3018.811025</td>\n",
       "      <td>3025.318396</td>\n",
       "      <td>2856.668299</td>\n",
       "      <td>2972.368553</td>\n",
       "      <td>3057.709996</td>\n",
       "      <td>3000.324431</td>\n",
       "      <td>2971.888456</td>\n",
       "      <td>...</td>\n",
       "      <td>2441.626947</td>\n",
       "      <td>2857.472112</td>\n",
       "      <td>2802.037454</td>\n",
       "      <td>2875.710501</td>\n",
       "      <td>2871.779460</td>\n",
       "      <td>3092.679907</td>\n",
       "      <td>3160.381906</td>\n",
       "      <td>2985.329695</td>\n",
       "      <td>2945.388284</td>\n",
       "      <td>2941.362087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miro_Hilvan-ne0041</th>\n",
       "      <td>2424.710645</td>\n",
       "      <td>2433.746054</td>\n",
       "      <td>2489.592979</td>\n",
       "      <td>2610.971424</td>\n",
       "      <td>2761.465876</td>\n",
       "      <td>2602.295700</td>\n",
       "      <td>2976.240354</td>\n",
       "      <td>2742.317394</td>\n",
       "      <td>2598.369992</td>\n",
       "      <td>2692.624715</td>\n",
       "      <td>...</td>\n",
       "      <td>2305.982656</td>\n",
       "      <td>2540.764537</td>\n",
       "      <td>2472.892209</td>\n",
       "      <td>2533.067438</td>\n",
       "      <td>2597.105828</td>\n",
       "      <td>2768.610224</td>\n",
       "      <td>2697.996574</td>\n",
       "      <td>2746.142717</td>\n",
       "      <td>2586.105174</td>\n",
       "      <td>2618.445356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miro_Vivir-ne0042</th>\n",
       "      <td>2692.634044</td>\n",
       "      <td>2714.389804</td>\n",
       "      <td>2842.195431</td>\n",
       "      <td>2848.758451</td>\n",
       "      <td>2778.458402</td>\n",
       "      <td>2761.898703</td>\n",
       "      <td>3116.691359</td>\n",
       "      <td>3046.434380</td>\n",
       "      <td>2944.264941</td>\n",
       "      <td>2979.822925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2869.551911</td>\n",
       "      <td>2747.674882</td>\n",
       "      <td>2786.228294</td>\n",
       "      <td>2945.634824</td>\n",
       "      <td>3037.245012</td>\n",
       "      <td>2995.165304</td>\n",
       "      <td>3048.043593</td>\n",
       "      <td>2890.888186</td>\n",
       "      <td>2877.501640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pereda_Pedro-ne0144</th>\n",
       "      <td>2129.738339</td>\n",
       "      <td>2208.201252</td>\n",
       "      <td>2324.406443</td>\n",
       "      <td>2364.020159</td>\n",
       "      <td>2728.936723</td>\n",
       "      <td>2399.087185</td>\n",
       "      <td>2709.556446</td>\n",
       "      <td>2247.974230</td>\n",
       "      <td>2241.958666</td>\n",
       "      <td>2150.504746</td>\n",
       "      <td>...</td>\n",
       "      <td>2869.551911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1565.288581</td>\n",
       "      <td>1771.109046</td>\n",
       "      <td>2267.932760</td>\n",
       "      <td>2450.923351</td>\n",
       "      <td>2543.578656</td>\n",
       "      <td>2269.999912</td>\n",
       "      <td>2180.779468</td>\n",
       "      <td>2251.371818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pereda_Penas-ne0145</th>\n",
       "      <td>2052.474196</td>\n",
       "      <td>2213.707590</td>\n",
       "      <td>2349.662223</td>\n",
       "      <td>2376.773223</td>\n",
       "      <td>2569.968181</td>\n",
       "      <td>2362.920219</td>\n",
       "      <td>2700.670607</td>\n",
       "      <td>2264.813618</td>\n",
       "      <td>2283.567180</td>\n",
       "      <td>2142.769529</td>\n",
       "      <td>...</td>\n",
       "      <td>2747.674882</td>\n",
       "      <td>1565.288581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1718.018173</td>\n",
       "      <td>2328.489178</td>\n",
       "      <td>2577.140718</td>\n",
       "      <td>2586.260653</td>\n",
       "      <td>2379.814122</td>\n",
       "      <td>2213.375150</td>\n",
       "      <td>2313.397777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pereda_Sotileza-ne0146</th>\n",
       "      <td>2097.021096</td>\n",
       "      <td>2159.672964</td>\n",
       "      <td>2439.833464</td>\n",
       "      <td>2445.424526</td>\n",
       "      <td>2670.966947</td>\n",
       "      <td>2485.379047</td>\n",
       "      <td>2898.486426</td>\n",
       "      <td>2397.839703</td>\n",
       "      <td>2366.994209</td>\n",
       "      <td>2224.926537</td>\n",
       "      <td>...</td>\n",
       "      <td>2786.228294</td>\n",
       "      <td>1771.109046</td>\n",
       "      <td>1718.018173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2219.183928</td>\n",
       "      <td>2563.267071</td>\n",
       "      <td>2738.769592</td>\n",
       "      <td>2592.744943</td>\n",
       "      <td>2239.824755</td>\n",
       "      <td>2471.400724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Picon_Dulce-ne0155</th>\n",
       "      <td>2181.173081</td>\n",
       "      <td>2274.322568</td>\n",
       "      <td>2333.246418</td>\n",
       "      <td>2445.485729</td>\n",
       "      <td>2870.449013</td>\n",
       "      <td>2590.448137</td>\n",
       "      <td>2911.209593</td>\n",
       "      <td>2282.923914</td>\n",
       "      <td>2309.467804</td>\n",
       "      <td>2263.362507</td>\n",
       "      <td>...</td>\n",
       "      <td>2945.634824</td>\n",
       "      <td>2267.932760</td>\n",
       "      <td>2328.489178</td>\n",
       "      <td>2219.183928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2194.090042</td>\n",
       "      <td>2543.326203</td>\n",
       "      <td>2445.582760</td>\n",
       "      <td>2214.082128</td>\n",
       "      <td>2506.289757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Picon_JuanV-ne0162</th>\n",
       "      <td>2537.517957</td>\n",
       "      <td>2560.370894</td>\n",
       "      <td>2699.575492</td>\n",
       "      <td>2597.534945</td>\n",
       "      <td>2991.170549</td>\n",
       "      <td>2714.085476</td>\n",
       "      <td>3001.134998</td>\n",
       "      <td>2548.352462</td>\n",
       "      <td>2633.959138</td>\n",
       "      <td>2505.718200</td>\n",
       "      <td>...</td>\n",
       "      <td>3037.245012</td>\n",
       "      <td>2450.923351</td>\n",
       "      <td>2577.140718</td>\n",
       "      <td>2563.267071</td>\n",
       "      <td>2194.090042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2589.083055</td>\n",
       "      <td>2643.472573</td>\n",
       "      <td>2515.879047</td>\n",
       "      <td>2730.508264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Picon_Lazaro-ne0161</th>\n",
       "      <td>2568.952628</td>\n",
       "      <td>2618.898680</td>\n",
       "      <td>2661.347957</td>\n",
       "      <td>2617.380280</td>\n",
       "      <td>2845.063189</td>\n",
       "      <td>2660.198587</td>\n",
       "      <td>2979.386879</td>\n",
       "      <td>2607.618169</td>\n",
       "      <td>2607.336197</td>\n",
       "      <td>2689.517108</td>\n",
       "      <td>...</td>\n",
       "      <td>2995.165304</td>\n",
       "      <td>2543.578656</td>\n",
       "      <td>2586.260653</td>\n",
       "      <td>2738.769592</td>\n",
       "      <td>2543.326203</td>\n",
       "      <td>2589.083055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2596.711649</td>\n",
       "      <td>2580.546868</td>\n",
       "      <td>2532.245235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valera_Genio-ne0151</th>\n",
       "      <td>2467.284030</td>\n",
       "      <td>2504.649140</td>\n",
       "      <td>2502.916654</td>\n",
       "      <td>2644.515895</td>\n",
       "      <td>2963.664838</td>\n",
       "      <td>2677.056816</td>\n",
       "      <td>2779.595212</td>\n",
       "      <td>2384.867753</td>\n",
       "      <td>2513.086162</td>\n",
       "      <td>2457.253401</td>\n",
       "      <td>...</td>\n",
       "      <td>3048.043593</td>\n",
       "      <td>2269.999912</td>\n",
       "      <td>2379.814122</td>\n",
       "      <td>2592.744943</td>\n",
       "      <td>2445.582760</td>\n",
       "      <td>2643.472573</td>\n",
       "      <td>2596.711649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1917.763868</td>\n",
       "      <td>1903.976271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valera_Juanita-ne0152</th>\n",
       "      <td>2152.521632</td>\n",
       "      <td>2284.564593</td>\n",
       "      <td>2430.757873</td>\n",
       "      <td>2452.854914</td>\n",
       "      <td>2751.053181</td>\n",
       "      <td>2477.597820</td>\n",
       "      <td>2799.188649</td>\n",
       "      <td>2252.733794</td>\n",
       "      <td>2264.576739</td>\n",
       "      <td>2186.799020</td>\n",
       "      <td>...</td>\n",
       "      <td>2890.888186</td>\n",
       "      <td>2180.779468</td>\n",
       "      <td>2213.375150</td>\n",
       "      <td>2239.824755</td>\n",
       "      <td>2214.082128</td>\n",
       "      <td>2515.879047</td>\n",
       "      <td>2580.546868</td>\n",
       "      <td>1917.763868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.304122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valera_Morsamor-ne0153</th>\n",
       "      <td>2373.088271</td>\n",
       "      <td>2391.257775</td>\n",
       "      <td>2510.821798</td>\n",
       "      <td>2589.977293</td>\n",
       "      <td>2785.147995</td>\n",
       "      <td>2500.963617</td>\n",
       "      <td>2840.853888</td>\n",
       "      <td>2451.050301</td>\n",
       "      <td>2522.379293</td>\n",
       "      <td>2516.545984</td>\n",
       "      <td>...</td>\n",
       "      <td>2877.501640</td>\n",
       "      <td>2251.371818</td>\n",
       "      <td>2313.397777</td>\n",
       "      <td>2471.400724</td>\n",
       "      <td>2506.289757</td>\n",
       "      <td>2730.508264</td>\n",
       "      <td>2532.245235</td>\n",
       "      <td>1903.976271</td>\n",
       "      <td>2020.304122</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Bazan_Pazos-ne0077  Bazan_Piedra-ne0082  \\\n",
       "Bazan_Pazos-ne0077                     0.000000          1888.524539   \n",
       "Bazan_Piedra-ne0082                 1888.524539             0.000000   \n",
       "Bazan_Sirena-ne0085                 2133.656036          2101.686163   \n",
       "BlascoIbanez_Arroz-ne0163           2261.449505          2413.229246   \n",
       "BlascoIbanez_Barraca-ne0164         2485.517472          2618.030424   \n",
       "BlascoIbanez_Bodega-ne0019          2292.546769          2411.142179   \n",
       "Clarin_Cuesta-ne0170                2833.751001          2788.718422   \n",
       "Clarin_Hijo-ne0135                  2255.722779          2371.096634   \n",
       "Clarin_Regenta-ne0325               2107.903106          2301.665414   \n",
       "Galdos_Bringas-ne0027               2165.846870          2303.483447   \n",
       "Galdos_Misericordia-ne0002          2096.965986          2197.289864   \n",
       "Galdos_Tristana-ne0005              2308.957339          2303.044233   \n",
       "Miro_Amigo-ne0044                   2833.990414          2787.848589   \n",
       "Miro_Hilvan-ne0041                  2424.710645          2433.746054   \n",
       "Miro_Vivir-ne0042                   2692.634044          2714.389804   \n",
       "Pereda_Pedro-ne0144                 2129.738339          2208.201252   \n",
       "Pereda_Penas-ne0145                 2052.474196          2213.707590   \n",
       "Pereda_Sotileza-ne0146              2097.021096          2159.672964   \n",
       "Picon_Dulce-ne0155                  2181.173081          2274.322568   \n",
       "Picon_JuanV-ne0162                  2537.517957          2560.370894   \n",
       "Picon_Lazaro-ne0161                 2568.952628          2618.898680   \n",
       "Valera_Genio-ne0151                 2467.284030          2504.649140   \n",
       "Valera_Juanita-ne0152               2152.521632          2284.564593   \n",
       "Valera_Morsamor-ne0153              2373.088271          2391.257775   \n",
       "\n",
       "                             Bazan_Sirena-ne0085  BlascoIbanez_Arroz-ne0163  \\\n",
       "Bazan_Pazos-ne0077                   2133.656036                2261.449505   \n",
       "Bazan_Piedra-ne0082                  2101.686163                2413.229246   \n",
       "Bazan_Sirena-ne0085                     0.000000                2574.080062   \n",
       "BlascoIbanez_Arroz-ne0163            2574.080062                   0.000000   \n",
       "BlascoIbanez_Barraca-ne0164          2869.269357                2140.168343   \n",
       "BlascoIbanez_Bodega-ne0019           2603.611752                1923.197453   \n",
       "Clarin_Cuesta-ne0170                 2694.868250                2955.406759   \n",
       "Clarin_Hijo-ne0135                   2494.749683                2380.717076   \n",
       "Clarin_Regenta-ne0325                2469.059592                2307.240663   \n",
       "Galdos_Bringas-ne0027                2422.727418                2367.146174   \n",
       "Galdos_Misericordia-ne0002           2354.063441                2427.345421   \n",
       "Galdos_Tristana-ne0005               2322.562916                2554.253675   \n",
       "Miro_Amigo-ne0044                    2708.059847                3018.811025   \n",
       "Miro_Hilvan-ne0041                   2489.592979                2610.971424   \n",
       "Miro_Vivir-ne0042                    2842.195431                2848.758451   \n",
       "Pereda_Pedro-ne0144                  2324.406443                2364.020159   \n",
       "Pereda_Penas-ne0145                  2349.662223                2376.773223   \n",
       "Pereda_Sotileza-ne0146               2439.833464                2445.424526   \n",
       "Picon_Dulce-ne0155                   2333.246418                2445.485729   \n",
       "Picon_JuanV-ne0162                   2699.575492                2597.534945   \n",
       "Picon_Lazaro-ne0161                  2661.347957                2617.380280   \n",
       "Valera_Genio-ne0151                  2502.916654                2644.515895   \n",
       "Valera_Juanita-ne0152                2430.757873                2452.854914   \n",
       "Valera_Morsamor-ne0153               2510.821798                2589.977293   \n",
       "\n",
       "                             BlascoIbanez_Barraca-ne0164  \\\n",
       "Bazan_Pazos-ne0077                           2485.517472   \n",
       "Bazan_Piedra-ne0082                          2618.030424   \n",
       "Bazan_Sirena-ne0085                          2869.269357   \n",
       "BlascoIbanez_Arroz-ne0163                    2140.168343   \n",
       "BlascoIbanez_Barraca-ne0164                     0.000000   \n",
       "BlascoIbanez_Bodega-ne0019                   2087.081492   \n",
       "Clarin_Cuesta-ne0170                         3183.523131   \n",
       "Clarin_Hijo-ne0135                           2753.838045   \n",
       "Clarin_Regenta-ne0325                        2679.923329   \n",
       "Galdos_Bringas-ne0027                        2780.074767   \n",
       "Galdos_Misericordia-ne0002                   2756.083968   \n",
       "Galdos_Tristana-ne0005                       2951.060462   \n",
       "Miro_Amigo-ne0044                            3025.318396   \n",
       "Miro_Hilvan-ne0041                           2761.465876   \n",
       "Miro_Vivir-ne0042                            2778.458402   \n",
       "Pereda_Pedro-ne0144                          2728.936723   \n",
       "Pereda_Penas-ne0145                          2569.968181   \n",
       "Pereda_Sotileza-ne0146                       2670.966947   \n",
       "Picon_Dulce-ne0155                           2870.449013   \n",
       "Picon_JuanV-ne0162                           2991.170549   \n",
       "Picon_Lazaro-ne0161                          2845.063189   \n",
       "Valera_Genio-ne0151                          2963.664838   \n",
       "Valera_Juanita-ne0152                        2751.053181   \n",
       "Valera_Morsamor-ne0153                       2785.147995   \n",
       "\n",
       "                             BlascoIbanez_Bodega-ne0019  Clarin_Cuesta-ne0170  \\\n",
       "Bazan_Pazos-ne0077                          2292.546769           2833.751001   \n",
       "Bazan_Piedra-ne0082                         2411.142179           2788.718422   \n",
       "Bazan_Sirena-ne0085                         2603.611752           2694.868250   \n",
       "BlascoIbanez_Arroz-ne0163                   1923.197453           2955.406759   \n",
       "BlascoIbanez_Barraca-ne0164                 2087.081492           3183.523131   \n",
       "BlascoIbanez_Bodega-ne0019                     0.000000           2951.362769   \n",
       "Clarin_Cuesta-ne0170                        2951.362769              0.000000   \n",
       "Clarin_Hijo-ne0135                          2460.758914           2599.740875   \n",
       "Clarin_Regenta-ne0325                       2381.056994           2704.231502   \n",
       "Galdos_Bringas-ne0027                       2545.838272           2874.876338   \n",
       "Galdos_Misericordia-ne0002                  2474.671621           2891.230643   \n",
       "Galdos_Tristana-ne0005                      2628.540593           2760.622010   \n",
       "Miro_Amigo-ne0044                           2856.668299           2972.368553   \n",
       "Miro_Hilvan-ne0041                          2602.295700           2976.240354   \n",
       "Miro_Vivir-ne0042                           2761.898703           3116.691359   \n",
       "Pereda_Pedro-ne0144                         2399.087185           2709.556446   \n",
       "Pereda_Penas-ne0145                         2362.920219           2700.670607   \n",
       "Pereda_Sotileza-ne0146                      2485.379047           2898.486426   \n",
       "Picon_Dulce-ne0155                          2590.448137           2911.209593   \n",
       "Picon_JuanV-ne0162                          2714.085476           3001.134998   \n",
       "Picon_Lazaro-ne0161                         2660.198587           2979.386879   \n",
       "Valera_Genio-ne0151                         2677.056816           2779.595212   \n",
       "Valera_Juanita-ne0152                       2477.597820           2799.188649   \n",
       "Valera_Morsamor-ne0153                      2500.963617           2840.853888   \n",
       "\n",
       "                             Clarin_Hijo-ne0135  Clarin_Regenta-ne0325  \\\n",
       "Bazan_Pazos-ne0077                  2255.722779            2107.903106   \n",
       "Bazan_Piedra-ne0082                 2371.096634            2301.665414   \n",
       "Bazan_Sirena-ne0085                 2494.749683            2469.059592   \n",
       "BlascoIbanez_Arroz-ne0163           2380.717076            2307.240663   \n",
       "BlascoIbanez_Barraca-ne0164         2753.838045            2679.923329   \n",
       "BlascoIbanez_Bodega-ne0019          2460.758914            2381.056994   \n",
       "Clarin_Cuesta-ne0170                2599.740875            2704.231502   \n",
       "Clarin_Hijo-ne0135                     0.000000            1752.054597   \n",
       "Clarin_Regenta-ne0325               1752.054597               0.000000   \n",
       "Galdos_Bringas-ne0027               2291.415609            2287.294810   \n",
       "Galdos_Misericordia-ne0002          2402.142484            2349.429186   \n",
       "Galdos_Tristana-ne0005              2367.034402            2432.886012   \n",
       "Miro_Amigo-ne0044                   3057.709996            3000.324431   \n",
       "Miro_Hilvan-ne0041                  2742.317394            2598.369992   \n",
       "Miro_Vivir-ne0042                   3046.434380            2944.264941   \n",
       "Pereda_Pedro-ne0144                 2247.974230            2241.958666   \n",
       "Pereda_Penas-ne0145                 2264.813618            2283.567180   \n",
       "Pereda_Sotileza-ne0146              2397.839703            2366.994209   \n",
       "Picon_Dulce-ne0155                  2282.923914            2309.467804   \n",
       "Picon_JuanV-ne0162                  2548.352462            2633.959138   \n",
       "Picon_Lazaro-ne0161                 2607.618169            2607.336197   \n",
       "Valera_Genio-ne0151                 2384.867753            2513.086162   \n",
       "Valera_Juanita-ne0152               2252.733794            2264.576739   \n",
       "Valera_Morsamor-ne0153              2451.050301            2522.379293   \n",
       "\n",
       "                             Galdos_Bringas-ne0027           ...            \\\n",
       "Bazan_Pazos-ne0077                     2165.846870           ...             \n",
       "Bazan_Piedra-ne0082                    2303.483447           ...             \n",
       "Bazan_Sirena-ne0085                    2422.727418           ...             \n",
       "BlascoIbanez_Arroz-ne0163              2367.146174           ...             \n",
       "BlascoIbanez_Barraca-ne0164            2780.074767           ...             \n",
       "BlascoIbanez_Bodega-ne0019             2545.838272           ...             \n",
       "Clarin_Cuesta-ne0170                   2874.876338           ...             \n",
       "Clarin_Hijo-ne0135                     2291.415609           ...             \n",
       "Clarin_Regenta-ne0325                  2287.294810           ...             \n",
       "Galdos_Bringas-ne0027                     0.000000           ...             \n",
       "Galdos_Misericordia-ne0002             1910.380182           ...             \n",
       "Galdos_Tristana-ne0005                 2113.927698           ...             \n",
       "Miro_Amigo-ne0044                      2971.888456           ...             \n",
       "Miro_Hilvan-ne0041                     2692.624715           ...             \n",
       "Miro_Vivir-ne0042                      2979.822925           ...             \n",
       "Pereda_Pedro-ne0144                    2150.504746           ...             \n",
       "Pereda_Penas-ne0145                    2142.769529           ...             \n",
       "Pereda_Sotileza-ne0146                 2224.926537           ...             \n",
       "Picon_Dulce-ne0155                     2263.362507           ...             \n",
       "Picon_JuanV-ne0162                     2505.718200           ...             \n",
       "Picon_Lazaro-ne0161                    2689.517108           ...             \n",
       "Valera_Genio-ne0151                    2457.253401           ...             \n",
       "Valera_Juanita-ne0152                  2186.799020           ...             \n",
       "Valera_Morsamor-ne0153                 2516.545984           ...             \n",
       "\n",
       "                             Miro_Vivir-ne0042  Pereda_Pedro-ne0144  \\\n",
       "Bazan_Pazos-ne0077                 2692.634044          2129.738339   \n",
       "Bazan_Piedra-ne0082                2714.389804          2208.201252   \n",
       "Bazan_Sirena-ne0085                2842.195431          2324.406443   \n",
       "BlascoIbanez_Arroz-ne0163          2848.758451          2364.020159   \n",
       "BlascoIbanez_Barraca-ne0164        2778.458402          2728.936723   \n",
       "BlascoIbanez_Bodega-ne0019         2761.898703          2399.087185   \n",
       "Clarin_Cuesta-ne0170               3116.691359          2709.556446   \n",
       "Clarin_Hijo-ne0135                 3046.434380          2247.974230   \n",
       "Clarin_Regenta-ne0325              2944.264941          2241.958666   \n",
       "Galdos_Bringas-ne0027              2979.822925          2150.504746   \n",
       "Galdos_Misericordia-ne0002         2872.583415          2206.613315   \n",
       "Galdos_Tristana-ne0005             3027.095203          2266.909252   \n",
       "Miro_Amigo-ne0044                  2441.626947          2857.472112   \n",
       "Miro_Hilvan-ne0041                 2305.982656          2540.764537   \n",
       "Miro_Vivir-ne0042                     0.000000          2869.551911   \n",
       "Pereda_Pedro-ne0144                2869.551911             0.000000   \n",
       "Pereda_Penas-ne0145                2747.674882          1565.288581   \n",
       "Pereda_Sotileza-ne0146             2786.228294          1771.109046   \n",
       "Picon_Dulce-ne0155                 2945.634824          2267.932760   \n",
       "Picon_JuanV-ne0162                 3037.245012          2450.923351   \n",
       "Picon_Lazaro-ne0161                2995.165304          2543.578656   \n",
       "Valera_Genio-ne0151                3048.043593          2269.999912   \n",
       "Valera_Juanita-ne0152              2890.888186          2180.779468   \n",
       "Valera_Morsamor-ne0153             2877.501640          2251.371818   \n",
       "\n",
       "                             Pereda_Penas-ne0145  Pereda_Sotileza-ne0146  \\\n",
       "Bazan_Pazos-ne0077                   2052.474196             2097.021096   \n",
       "Bazan_Piedra-ne0082                  2213.707590             2159.672964   \n",
       "Bazan_Sirena-ne0085                  2349.662223             2439.833464   \n",
       "BlascoIbanez_Arroz-ne0163            2376.773223             2445.424526   \n",
       "BlascoIbanez_Barraca-ne0164          2569.968181             2670.966947   \n",
       "BlascoIbanez_Bodega-ne0019           2362.920219             2485.379047   \n",
       "Clarin_Cuesta-ne0170                 2700.670607             2898.486426   \n",
       "Clarin_Hijo-ne0135                   2264.813618             2397.839703   \n",
       "Clarin_Regenta-ne0325                2283.567180             2366.994209   \n",
       "Galdos_Bringas-ne0027                2142.769529             2224.926537   \n",
       "Galdos_Misericordia-ne0002           2143.877946             2118.256240   \n",
       "Galdos_Tristana-ne0005               2308.811201             2342.655215   \n",
       "Miro_Amigo-ne0044                    2802.037454             2875.710501   \n",
       "Miro_Hilvan-ne0041                   2472.892209             2533.067438   \n",
       "Miro_Vivir-ne0042                    2747.674882             2786.228294   \n",
       "Pereda_Pedro-ne0144                  1565.288581             1771.109046   \n",
       "Pereda_Penas-ne0145                     0.000000             1718.018173   \n",
       "Pereda_Sotileza-ne0146               1718.018173                0.000000   \n",
       "Picon_Dulce-ne0155                   2328.489178             2219.183928   \n",
       "Picon_JuanV-ne0162                   2577.140718             2563.267071   \n",
       "Picon_Lazaro-ne0161                  2586.260653             2738.769592   \n",
       "Valera_Genio-ne0151                  2379.814122             2592.744943   \n",
       "Valera_Juanita-ne0152                2213.375150             2239.824755   \n",
       "Valera_Morsamor-ne0153               2313.397777             2471.400724   \n",
       "\n",
       "                             Picon_Dulce-ne0155  Picon_JuanV-ne0162  \\\n",
       "Bazan_Pazos-ne0077                  2181.173081         2537.517957   \n",
       "Bazan_Piedra-ne0082                 2274.322568         2560.370894   \n",
       "Bazan_Sirena-ne0085                 2333.246418         2699.575492   \n",
       "BlascoIbanez_Arroz-ne0163           2445.485729         2597.534945   \n",
       "BlascoIbanez_Barraca-ne0164         2870.449013         2991.170549   \n",
       "BlascoIbanez_Bodega-ne0019          2590.448137         2714.085476   \n",
       "Clarin_Cuesta-ne0170                2911.209593         3001.134998   \n",
       "Clarin_Hijo-ne0135                  2282.923914         2548.352462   \n",
       "Clarin_Regenta-ne0325               2309.467804         2633.959138   \n",
       "Galdos_Bringas-ne0027               2263.362507         2505.718200   \n",
       "Galdos_Misericordia-ne0002          2128.506321         2547.426760   \n",
       "Galdos_Tristana-ne0005              2225.311701         2566.157941   \n",
       "Miro_Amigo-ne0044                   2871.779460         3092.679907   \n",
       "Miro_Hilvan-ne0041                  2597.105828         2768.610224   \n",
       "Miro_Vivir-ne0042                   2945.634824         3037.245012   \n",
       "Pereda_Pedro-ne0144                 2267.932760         2450.923351   \n",
       "Pereda_Penas-ne0145                 2328.489178         2577.140718   \n",
       "Pereda_Sotileza-ne0146              2219.183928         2563.267071   \n",
       "Picon_Dulce-ne0155                     0.000000         2194.090042   \n",
       "Picon_JuanV-ne0162                  2194.090042            0.000000   \n",
       "Picon_Lazaro-ne0161                 2543.326203         2589.083055   \n",
       "Valera_Genio-ne0151                 2445.582760         2643.472573   \n",
       "Valera_Juanita-ne0152               2214.082128         2515.879047   \n",
       "Valera_Morsamor-ne0153              2506.289757         2730.508264   \n",
       "\n",
       "                             Picon_Lazaro-ne0161  Valera_Genio-ne0151  \\\n",
       "Bazan_Pazos-ne0077                   2568.952628          2467.284030   \n",
       "Bazan_Piedra-ne0082                  2618.898680          2504.649140   \n",
       "Bazan_Sirena-ne0085                  2661.347957          2502.916654   \n",
       "BlascoIbanez_Arroz-ne0163            2617.380280          2644.515895   \n",
       "BlascoIbanez_Barraca-ne0164          2845.063189          2963.664838   \n",
       "BlascoIbanez_Bodega-ne0019           2660.198587          2677.056816   \n",
       "Clarin_Cuesta-ne0170                 2979.386879          2779.595212   \n",
       "Clarin_Hijo-ne0135                   2607.618169          2384.867753   \n",
       "Clarin_Regenta-ne0325                2607.336197          2513.086162   \n",
       "Galdos_Bringas-ne0027                2689.517108          2457.253401   \n",
       "Galdos_Misericordia-ne0002           2800.377069          2528.349219   \n",
       "Galdos_Tristana-ne0005               2714.227547          2368.039339   \n",
       "Miro_Amigo-ne0044                    3160.381906          2985.329695   \n",
       "Miro_Hilvan-ne0041                   2697.996574          2746.142717   \n",
       "Miro_Vivir-ne0042                    2995.165304          3048.043593   \n",
       "Pereda_Pedro-ne0144                  2543.578656          2269.999912   \n",
       "Pereda_Penas-ne0145                  2586.260653          2379.814122   \n",
       "Pereda_Sotileza-ne0146               2738.769592          2592.744943   \n",
       "Picon_Dulce-ne0155                   2543.326203          2445.582760   \n",
       "Picon_JuanV-ne0162                   2589.083055          2643.472573   \n",
       "Picon_Lazaro-ne0161                     0.000000          2596.711649   \n",
       "Valera_Genio-ne0151                  2596.711649             0.000000   \n",
       "Valera_Juanita-ne0152                2580.546868          1917.763868   \n",
       "Valera_Morsamor-ne0153               2532.245235          1903.976271   \n",
       "\n",
       "                             Valera_Juanita-ne0152  Valera_Morsamor-ne0153  \n",
       "Bazan_Pazos-ne0077                     2152.521632             2373.088271  \n",
       "Bazan_Piedra-ne0082                    2284.564593             2391.257775  \n",
       "Bazan_Sirena-ne0085                    2430.757873             2510.821798  \n",
       "BlascoIbanez_Arroz-ne0163              2452.854914             2589.977293  \n",
       "BlascoIbanez_Barraca-ne0164            2751.053181             2785.147995  \n",
       "BlascoIbanez_Bodega-ne0019             2477.597820             2500.963617  \n",
       "Clarin_Cuesta-ne0170                   2799.188649             2840.853888  \n",
       "Clarin_Hijo-ne0135                     2252.733794             2451.050301  \n",
       "Clarin_Regenta-ne0325                  2264.576739             2522.379293  \n",
       "Galdos_Bringas-ne0027                  2186.799020             2516.545984  \n",
       "Galdos_Misericordia-ne0002             2184.957919             2497.194151  \n",
       "Galdos_Tristana-ne0005                 2272.183304             2517.350645  \n",
       "Miro_Amigo-ne0044                      2945.388284             2941.362087  \n",
       "Miro_Hilvan-ne0041                     2586.105174             2618.445356  \n",
       "Miro_Vivir-ne0042                      2890.888186             2877.501640  \n",
       "Pereda_Pedro-ne0144                    2180.779468             2251.371818  \n",
       "Pereda_Penas-ne0145                    2213.375150             2313.397777  \n",
       "Pereda_Sotileza-ne0146                 2239.824755             2471.400724  \n",
       "Picon_Dulce-ne0155                     2214.082128             2506.289757  \n",
       "Picon_JuanV-ne0162                     2515.879047             2730.508264  \n",
       "Picon_Lazaro-ne0161                    2580.546868             2532.245235  \n",
       "Valera_Genio-ne0151                    1917.763868             1903.976271  \n",
       "Valera_Juanita-ne0152                     0.000000             2020.304122  \n",
       "Valera_Morsamor-ne0153                 2020.304122                0.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "I_love_this_deltamatrix = pd.DataFrame(np.array(I_love_this_stuff[0]), index=list(R.colnames(I_love_this_stuff[0])), columns=list(R.colnames(I_love_this_stuff[0])))\n",
    "\n",
    "I_love_this_deltamatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have your beautiful Delta Matrix of your corpus as Pandas Dataframe, using Stylo but working only with Python scripts. Yey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback, please!\n",
    "\n",
    "This is just a try. Many things could be done in different ways, I probably have overseen things, maybe there are better ways to deal with this Python-R problem... So, please, let me know your thoughts. Together with this notebook I have also written a blog post, where you can write coments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
